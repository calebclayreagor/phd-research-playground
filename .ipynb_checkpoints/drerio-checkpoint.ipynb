{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neuromast single cell pipeline \n",
    "\n",
    "* cluster gene trajectories into modules\n",
    "* analyze pathway enrichment in pseudotime\n",
    "* differential expression analysis of hair cell polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, h5py\n",
    "import sklearn, umap, rpy2\n",
    "import arboreto, kneed\n",
    "import matplotlib, matplotlib_venn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# custom class for sc datasets\n",
    "from dataset import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.dpi']= 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sc data from lush et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lush = dataset(name='lush et al')\n",
    "\n",
    "# load GEO dataset from hdf5 file\n",
    "f = h5py.File(('geo-datasets/'\n",
    "               'GSE123241.h5'),'r')\n",
    "    \n",
    "group = 'danRer10.Ens_84'\n",
    "\n",
    "lush.raw_counts_from_sparse_matrix(\n",
    "    \n",
    "    cell_names = [i.decode('ascii') for i in f[group]['barcodes'][:]],\n",
    "    gene_names = [i.decode('ascii') for i in f[group]['genes'][:]], \n",
    "    data = f[group]['data'], dtype = 'i4', indices = f[group]['indices'],\n",
    "    indptr = f[group]['indptr'], shape = tuple(reversed(f[group]['shape'])) )\n",
    "\n",
    "\n",
    "# pre-process, scale and impute expression\n",
    "# * filter rare genes and cells with low counts\n",
    "# * normalize library sizes, then log scale\n",
    "# * impute expression using data diffusion\n",
    "\n",
    "lush.preprocess_raw_counts(library_size_cutoff=0) # pre-filtered\n",
    "lush.impute_from_normalized(genes='all_genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudotime/clustering from lush fig 4I\n",
    "lush4i = pd.read_csv(('geo-datasets/'\n",
    "                      'lush_fig4i.csv'),\n",
    "                     index_col=0)\n",
    "\n",
    "lush4i.sort_values('pseudotime',inplace=True)\n",
    "\n",
    "# load lateral line system genes from refs\n",
    "lat_line = pd.read_csv('refs/drerio_latline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## differentiating hair cell trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_traj = dataset(name='diff hair cell trajectory')\n",
    "\n",
    "# cell barcodes for cells in the trajectory\n",
    "trajectory = lush4i.loc[lush4i['cluster'].isin([14,4,2,1])].index\n",
    "\n",
    "# assign expression values from lush dataset\n",
    "diff_traj.raw_counts = lush.raw_counts.loc[trajectory]\n",
    "diff_traj.normalized = lush.normalized.loc[trajectory]\n",
    "diff_traj.imputed = lush.imputed.loc[trajectory]\n",
    "\n",
    "# assign pseudotime/clustering from lush et al fig 4I\n",
    "diff_traj.pseudotimes = lush4i.loc[trajectory,'pseudotime']\n",
    "diff_traj.clusters = lush4i.loc[trajectory,'cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster genes -> modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin data along pseudotime and expression axes\n",
    "# * this spaces the data more evenly (in pseudotime)\n",
    "# * and allows us to calculate MI (by expression)\n",
    "\n",
    "diff_traj.bin_data(data = 'imputed', in_pt = True, pt_bin = 0.025,\n",
    "                   genes = lat_line['Ensembl_id'].unique())\n",
    "\n",
    "\n",
    "# find pairwise gene similarities (adjusted MI)\n",
    "diff_traj.find_gene_similarities(n_runs=10)                             ##### use n_runs = 10 when finished editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral clustering, choose n clusters by max silhouette\n",
    "diff_traj.cluster_genes(n_components=2, max_clusters=20, plot_silhouette=True)     ##### and remove max_clusters kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average trajectory and errors for gene modules\n",
    "diff_traj.plot_modules(data='imputed', smoothing=0.1)\n",
    "\n",
    "for ax in diff_traj.module_axes:\n",
    "    y, a, z, v = 0.5, 0.33, 0, 'center'\n",
    "    ax.text(diff_traj.pseudotimes.iloc[np.where(diff_traj.clusters==14)].min(),\n",
    "            y, 'central s.c.', va=v, ha='left', alpha=a, zorder=z)\n",
    "    ax.text(diff_traj.pseudotimes.iloc[np.where(diff_traj.clusters==4)].max(),\n",
    "            y, 'diff. s.c.', va=v, ha='left', alpha=a, zorder=z)\n",
    "    ax.text(diff_traj.pseudotimes.iloc[np.where(diff_traj.clusters==2)].mean(),\n",
    "            y, 'young h.c.', va=v, ha='center', alpha=a, zorder=z)\n",
    "    ax.text(diff_traj.pseudotimes.iloc[np.where(diff_traj.clusters==1)].mean(),\n",
    "            y, 'mature h.c.', va=v, ha='center', alpha=a, zorder=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pathway enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order genes along pseudotime axis\n",
    "diff_traj.order_genes_pt(method='max')\n",
    "\n",
    "\n",
    "# bin genes in pseudotime and perform GO analysis\n",
    "# * term enrichment for KEGG pathways via Enrichr\n",
    "\n",
    "diff_traj.pathway_ea_in_pt(pathways = ['Cell cycle',\n",
    "                           'Notch signaling pathway',\n",
    "                           'Wnt signaling pathway',\n",
    "                           'Hedgehog signaling pathway',\n",
    "                           'TGF-beta signaling pathway'],\n",
    "                            pt_bin=0.1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "#-------------------------------------------------#\n",
    "###\n",
    "# label cells by cluster from Lush et al. and genes \n",
    "# by mouse homologues for later dataset integration\n",
    "###\n",
    "fishEns_to_mouseName = pd.read_csv(('metaAnalysis/'\n",
    "                                    'refs/'\n",
    "                                    'fishEns_to'\n",
    "                                    '_mouseName.csv'),\n",
    "                                    index_col=0)\n",
    "\n",
    "labeled_data = pd.DataFrame(data_copy.values,\n",
    "                            index=data_copy.index.values,\n",
    "                            columns=data_copy.columns.values)\n",
    "\n",
    "labeled_data = labeled_data.loc[:,[x for x in \n",
    "                    labeled_data.columns.values if x in \n",
    "                      fishEns_to_mouseName.index.values]]\n",
    "\n",
    "labeled_data.columns = [fishEns_to_mouseName.loc[x,'Associated Gene Name'].values[0] if \n",
    "                        type(fishEns_to_mouseName.loc[x,'Associated Gene Name'])!=str \n",
    "                        else fishEns_to_mouseName.loc[x,'Associated Gene Name'] for x in \n",
    "                        labeled_data.columns.values]\n",
    "\n",
    "labeled_data['node'] = labeled_data.index.to_series(\n",
    "                        ).map(dict(zip(p4i_data.index,\n",
    "                                       p4i_data['node'])))\n",
    "#--------------------------------------------------------#\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "#######################################  PART 2:  POLARITY   ######################################################\n",
    "###################################################################################################################\n",
    "\n",
    "#---------------------------------#\n",
    "########## polarity tsne ##########\n",
    "#---------------------------------#\n",
    "\n",
    "\n",
    "try:\n",
    "    labels = pd.read_csv(('polarityInference/'\n",
    "                          'refs/'\n",
    "                          'labels.csv'),\n",
    "                          index_col=0)\n",
    "    \n",
    "    embedding = pd.read_csv(('polarityInference/'\n",
    "                             'embeddings/'\n",
    "                             'tsne.csv'),\n",
    "                             index_col=0)\n",
    "\n",
    "except:\n",
    "    \n",
    "    #----------------------------#\n",
    "    ### select cells and genes ###\n",
    "    cells = sorted_data.index.values[\n",
    "             np.where((sorted_data['node']==14)|\n",
    "             (sorted_data['node']==4))]\n",
    "    \n",
    "    polarity_genes = pd.read_csv(('polarityInference/'\n",
    "                                  'refs/'\n",
    "                                  'polarity_genes.csv'))\n",
    "                                 \n",
    "    genes = [x for x in sorted_data.columns.values \n",
    "             if x in polarity_genes['Ensembl_id'].values]\n",
    "    #---------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    #------------------------------#\n",
    "    ### dimensionality reduction ###\n",
    "    pca_embedding = sklearn.decomposition.PCA(\n",
    "                     n_components=4).fit_transform(\n",
    "                     sorted_data.loc[cells,genes])\n",
    "    \n",
    "    tsne_embedding = sklearn.manifold.TSNE(\n",
    "                        ).fit_transform(pca_embedding)\n",
    "    \n",
    "    embedding = pd.DataFrame(tsne_embedding,\n",
    "                             index=cells,\n",
    "                             columns=['TSNE1',\n",
    "                                      'TSNE2'])\n",
    "    #-----------------------------------------#\n",
    "    \n",
    "    \n",
    "    #------------------------------#\n",
    "    ### annotate cell polarities ###\n",
    "    labels_df = pd.DataFrame(index=cells,\n",
    "                             columns=['Label'])\n",
    "    \n",
    "    labels_df.loc[cells[np.where(sorted_data['node']==14)],'Label'] = 0\n",
    "    \n",
    "    for cell in cells[np.where(sorted_data['node']==4)]:\n",
    "        \n",
    "        plt.figure(figsize=(8,7.5))\n",
    "        plt.scatter(embedding['TSNE1'],\n",
    "                    embedding['TSNE2'],\n",
    "                    zorder=0,\n",
    "                    c='k',\n",
    "                    s=15)\n",
    "        \n",
    "        plt.scatter(embedding.loc[cells[np.where(labels_df['Label']==0)],'TSNE1'],\n",
    "                    embedding.loc[cells[np.where(labels_df['Label']==0)],'TSNE2'],\n",
    "                    c='r',\n",
    "                    s=15)\n",
    "        \n",
    "        plt.scatter(embedding.loc[cells[np.where(labels_df['Label']==1)],'TSNE1'],\n",
    "                    embedding.loc[cells[np.where(labels_df['Label']==1)],'TSNE2'],\n",
    "                    c='b',\n",
    "                    s=15)\n",
    "        \n",
    "        plt.scatter(embedding.loc[cells[np.where(labels_df['Label']==2)],'TSNE1'],\n",
    "                    embedding.loc[cells[np.where(labels_df['Label']==2)],'TSNE2'],\n",
    "                    c='g',\n",
    "                    s=15)\n",
    "        \n",
    "        plt.scatter(embedding.loc[cell,'TSNE1'],\n",
    "                    embedding.loc[cell,'TSNE2'],\n",
    "                    c='c',\n",
    "                    s=15)\n",
    "        \n",
    "        plt.show()\n",
    "        labels_df.loc[cell,'Label'] = int(input('cluster -> '))\n",
    "    \n",
    "    labels_df.to_csv(('polarityInference/'\n",
    "                      'refs/'\n",
    "                      'labels.csv'))\n",
    "                     \n",
    "    embedding.to_csv(('polarityInference/'\n",
    "                      'embeddings/'\n",
    "                      'tsne.csv'))\n",
    "    #----------------------------#\n",
    "\n",
    "                     \n",
    "\n",
    "#---------------#\n",
    "### plot tsne ###\n",
    "sz = 3\n",
    "lw = sz*0.1\n",
    "plt.figure(figsize=(1.25,1.25))\n",
    "\n",
    "# central support cells\n",
    "which = np.where(sorted_data['node']==14)\n",
    "\n",
    "plt.scatter(embedding.loc[\n",
    "            embedding.index.values[which],\n",
    "            embedding.columns.values[0]],\n",
    "            embedding.loc[\n",
    "            embedding.index.values[which],\n",
    "            embedding.columns.values[1]],\n",
    "            c='slateblue',\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            label=\"central sc's\",\n",
    "            s=sz)\n",
    "\n",
    "# differentiating support cells\n",
    "which = np.where(sorted_data['node']==4) \n",
    "\n",
    "plt.scatter(embedding.loc[\n",
    "            embedding.index.values[which],\n",
    "            embedding.columns.values[0]],\n",
    "            embedding.loc[\n",
    "            embedding.index.values[which],\n",
    "            embedding.columns.values[1]],\n",
    "            c='mediumseagreen',\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            label=\"diff. sc's\",\n",
    "            s=sz)\n",
    "\n",
    "# sender cells\n",
    "which = np.where((labels['Label']==1))\n",
    "\n",
    "plot_data = embedding.loc[\n",
    "            embedding.index.values[which],:].sort_values(\n",
    "            embedding.columns.values[0]).values\n",
    "\n",
    "plt.scatter(plot_data[:,0],\n",
    "            plot_data[:,1],\n",
    "            c='tab:orange',\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            label='sender \\n(caudad)',\n",
    "            s=sz)\n",
    "\n",
    "# receiver cells\n",
    "which = np.where((labels['Label']==2))\n",
    "\n",
    "plot_data = embedding.loc[\n",
    "            embedding.index.values[which],:].sort_values(\n",
    "            embedding.columns.values[0]).values\n",
    "\n",
    "plt.scatter(plot_data[:,0],\n",
    "            plot_data[:,1],\n",
    "            c='tab:purple',\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            label='receiver \\n(rostrad)',\n",
    "            s=sz)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axis('off')\n",
    "\n",
    "ax.legend(fontsize=3,\n",
    "          frameon=False,\n",
    "          markerscale=1.5,\n",
    "          loc='lower left',\n",
    "          borderaxespad=0,\n",
    "          bbox_to_anchor=(0.05,0.05))\n",
    "\n",
    "# axes annotation\n",
    "plt.annotate(s='',xy=(0,0.3),\n",
    "             xytext=(0.3,0),\n",
    "             xycoords=\n",
    "             'axes fraction',\n",
    "             arrowprops=\n",
    "             dict(arrowstyle=('<->,'\n",
    "             'head_width=0.05,'\n",
    "             'head_length=0.1'),\n",
    "             connectionstyle=\n",
    "             ('angle,rad=0,'\n",
    "              'angleA=0,'\n",
    "              'angleB=-90'),\n",
    "             color='k',\n",
    "             linewidth=0.5))\n",
    "\n",
    "plt.text(s='tSNE1',\n",
    "         x=0.13,\n",
    "         y=-0.05,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.text(s='tSNE2',\n",
    "         x=-0.05,\n",
    "         y=0.13,\n",
    "         rotation=90,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.savefig(('polarityInference/'\n",
    "             'figures/'\n",
    "             'tsne.png'),\n",
    "             dpi=dpi)\n",
    "#-------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------#\n",
    "########## differential expression analysis ##########\n",
    "#----------------------------------------------------#\n",
    "\n",
    "#-----------------------------#\n",
    "### additional dependencies ###\n",
    "from rpy2 import robjects\n",
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects import Formula\n",
    "robjects.numpy2ri.activate()\n",
    "from rpy2.robjects.packages import importr\n",
    "deseq = importr('DESeq2')\n",
    "base = importr(\"base\")\n",
    "dollar = base.__dict__[\"$\"]\n",
    "#-------------------------#\n",
    "\n",
    "try:\n",
    "    polarity_degs = pd.read_csv(('polarityInference/'\n",
    "                                 'results/'\n",
    "                                 'de.csv'),\n",
    "                                 index_col=0)\n",
    "\n",
    "except:\n",
    "\n",
    "    #-------------------------------#\n",
    "    cells = counts_data.index.values[\n",
    "            np.where((counts_data['node']==14)|\n",
    "                     (counts_data['node']==4))]\n",
    "    \n",
    "    rearranging_cells = cells[np.where(\n",
    "                            (labels['Label']==1)|\n",
    "                            (labels['Label']==2))]\n",
    "    \n",
    "    rearranging_cells_labels = labels.loc[labels.index.values[\n",
    "                                np.where((labels['Label']==1)|\n",
    "                                (labels['Label']==2))],:]\n",
    "    \n",
    "    genes = [x for x in counts_data.columns.values \n",
    "                                     if x != 'node']\n",
    "    #----------------------------------------------#\n",
    "    \n",
    "    \n",
    "    #------------#\n",
    "    ### deseq2 ###\n",
    "    labels_rdf = robjects.DataFrame({'polarity':robjects.IntVector(\n",
    "                    rearranging_cells_labels['Label'].values)})\n",
    "    \n",
    "    dds = deseq.DESeqDataSetFromMatrix(\n",
    "            countData=counts_data.loc[rearranging_cells,genes].values.T,\n",
    "            colData=labels_rdf,\n",
    "            design=Formula('~ polarity'))\n",
    "    \n",
    "    dds = deseq.DESeq(dds)\n",
    "    ds_res = deseq.results(dds)\n",
    "\n",
    "    polarity_degs = pd.DataFrame(index=genes)\n",
    "    \n",
    "    polarity_degs['P.Value'] = dollar(ds_res,'pvalue')\n",
    "    \n",
    "    polarity_degs['adj.P.Val'] = dollar(ds_res,'padj')\n",
    "    \n",
    "    polarity_degs['logFC'] = dollar(ds_res,'log2FoldChange')\n",
    "    \n",
    "    polarity_degs['gene'] = [gene_names_lush[genes_lush.index(idx)] \n",
    "                             for idx in polarity_degs.index.values]\n",
    "    \n",
    "    polarity_degs['lateral line'] = [True if idx in \n",
    "                                     lateral_line_genes['Ensembl_id'].values \n",
    "                                     else False for idx in \n",
    "                                     deg_polarities.index.values]\n",
    "    \n",
    "    polarity_degs.sort_values('P.Value',\n",
    "                              inplace=True)\n",
    "    \n",
    "    polarity_degs.to_csv(('polarityInference/'\n",
    "                          'results/'\n",
    "                          'de.csv'))\n",
    "    #------------------------------#\n",
    "    \n",
    "\n",
    "    \n",
    "#------------------#\n",
    "### plot results ###\n",
    "fig,ax = plt.subplots(1,4,\n",
    "            figsize=(10,3))\n",
    "\n",
    "# individual genes of interest\n",
    "genes_plot = ['ENSDARG00000052139',\n",
    "              'ENSDARG00000039701',\n",
    "              'ENSDARG00000054562']\n",
    "\n",
    "gene_names_plot = ['notch3',\n",
    "                   'emx2',\n",
    "                   'her15.1']\n",
    "\n",
    "gene_colors = ['blue',\n",
    "               'green',\n",
    "               'red']\n",
    "\n",
    "# volcano plots\n",
    "genes_volcano = [x for x in polarity_degs.index.values \n",
    "                 if x in lateral_line_genes['Ensembl_id'].values]\n",
    "\n",
    "ax[0].scatter(polarity_degs.loc[genes_volcano,'logFC'],\n",
    "              -np.log10(polarity_degs.loc[genes_volcano,'P.Value']),\n",
    "              c='k',\n",
    "              s=10)\n",
    "\n",
    "xl,xh = ax[0].get_xlim()\n",
    "\n",
    "ax[0].hlines(-np.log10(0.05),\n",
    "             xl,xh,\n",
    "             linestyle='--')\n",
    "\n",
    "ax[0].set_xlabel('log2 FC')\n",
    "ax[0].set_ylabel('-log10 p value')\n",
    "\n",
    "# violin plots\n",
    "cells = counts_data.index.values[\n",
    "        np.where((counts_data['node']==14)|\n",
    "                 (counts_data['node']==4))]\n",
    "\n",
    "for i in genes_plot:\n",
    "    \n",
    "    n = genes_plot.index(i)\n",
    "    \n",
    "    data = [counts_data.loc[cells,i].values[np.where(labels['Label']==1)],\n",
    "            counts_data.loc[cells,i].values[np.where(labels['Label']==2)]]\n",
    "    \n",
    "    v = ax[n+1].violinplot(data,\n",
    "                           showmeans=False,\n",
    "                           showmedians=False,\n",
    "                           showextrema=False)\n",
    "    \n",
    "    # sender cells\n",
    "    v['bodies'][0].set_facecolor('tab:orange')\n",
    "    v['bodies'][0].set_edgecolor('k')\n",
    "    v['bodies'][0].set_alpha(1)\n",
    "    \n",
    "    # receiver cells\n",
    "    v['bodies'][1].set_facecolor('tab:purple')\n",
    "    v['bodies'][1].set_edgecolor('k')\n",
    "    v['bodies'][1].set_alpha(1)\n",
    "    \n",
    "    ax[n+1].scatter([1,2],\n",
    "                    [np.median(x) \n",
    "                     for x in data],\n",
    "                    marker='o',\n",
    "                    color=gene_colors[n],\n",
    "                    s=30,\n",
    "                    zorder=3)\n",
    "    \n",
    "    ax[n+1].vlines([1,2],\n",
    "                   [np.quantile(x,0.25)\n",
    "                    for x in data],\n",
    "                   [np.quantile(x,0.75)\n",
    "                    for x in data],\n",
    "                   color='k',\n",
    "                   linestyle='-',\n",
    "                   lw=5)\n",
    "    \n",
    "    ax[n+1].vlines([1,2],\n",
    "                   [min(x) for \n",
    "                    x in data],\n",
    "                   [max(x) for \n",
    "                    x in data],\n",
    "                   color='k',\n",
    "                   linestyle='-',\n",
    "                   lw=1)\n",
    "\n",
    "    # significance bars\n",
    "    _,yh = ax[n+1].get_ylim()\n",
    "    \n",
    "    ax[n+1].plot([1,1,2,2],\n",
    "                 [yh,yh+0.05*yh,\n",
    "                  yh+0.05*yh,yh],\n",
    "                 linewidth=1,\n",
    "                 color='k')\n",
    "    \n",
    "    if polarity_degs.loc[genes_plot[n],'P.Value'] < 0.05:\n",
    "        \n",
    "        ax[n+1].text(1.5,\n",
    "                     yh+0.055*yh,\n",
    "                     s='*',\n",
    "                     ha='center',\n",
    "                     va='bottom')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ax[n+1].text(1.5,\n",
    "                     yh+0.075*yh,\n",
    "                     s='n.s.',\n",
    "                     ha='center',\n",
    "                     va='bottom')\n",
    "    \n",
    "    ax[n+1].set_ylim(top=yh+0.2*yh)\n",
    "    ax[n+1].title.set_text(gene_names_plot[n])\n",
    "    \n",
    "    ax[n+1].set_xticklabels(['','sender',\n",
    "                             '','receiver'])\n",
    "    \n",
    "    if n == 0:\n",
    "        ax[n+1].set_ylabel('transcripts')\n",
    "        \n",
    "    # add to volcano\n",
    "    ax[0].scatter(polarity_degs.loc[i,'logFC'],\n",
    "                  -np.log10(polarity_degs.loc[i,'P.Value']),\n",
    "                  c=gene_colors[n],\n",
    "                  s=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(('polarityInference/'\n",
    "             'figures/'\n",
    "             'de.png'),\n",
    "             dpi=dpi)\n",
    "#-------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "#######################################  PART 3: META-ANALYSIS   ##################################################\n",
    "###################################################################################################################\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "########## preprocess mouse data for alignment ##########\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "try:\n",
    "    metadata = pd.read_csv(('metaAnalysis/'\n",
    "                            'datasets/'\n",
    "                            'metadata.csv'),\n",
    "                            index_col=0)\n",
    "    \n",
    "    lush = pd.read_csv(('metaAnalysis/'\n",
    "                        'datasets/'\n",
    "                        'lush.csv'),\n",
    "                        index_col=0)\n",
    "    \n",
    "    burns = pd.read_csv(('metaAnalysis/'\n",
    "                         'datasets/'\n",
    "                         'burns.csv'),\n",
    "                         index_col=0)\n",
    "    \n",
    "    hoa = pd.read_csv(('metaAnalysis/'\n",
    "                       'datasets/'\n",
    "                       'hoa.csv'),\n",
    "                       index_col=0)\n",
    "\n",
    "except:  \n",
    "    print('loading datasets...')\n",
    "    \n",
    "    #---------------------------------------#\n",
    "    ### load Burns et al. data (GSE71982) ###\n",
    "    burns_t = pd.read_csv(('GSE71982/'\n",
    "                           'GSE71982_'\n",
    "                           'RSEM_Counts_'\n",
    "                           'Matrix.csv'),\n",
    "                           index_col=0)\n",
    "    \n",
    "    burns_phenoData_utric = pd.read_csv(('GSE71982/'\n",
    "                                         'GSE71982_'\n",
    "                                         'P1_Utricle_'\n",
    "                                         'PhenoData.csv'),\n",
    "                                         index_col=0)\n",
    "    \n",
    "    burns_phenoData_cochl1 = pd.read_csv(('GSE71982/'\n",
    "                                          'GSE71982_'\n",
    "                                          'P1_Coch__'\n",
    "                                          'nonFACs__'\n",
    "                                          'PhenoData.csv'),\n",
    "                                          index_col=0)\n",
    "    \n",
    "    burns_phenoData_cochl2 = pd.read_csv(('GSE71982/'\n",
    "                                          'GSE71982_'\n",
    "                                          'P1_Coch__'\n",
    "                                          'FACs__PhenoData.csv'),\n",
    "                                          index_col=0)\n",
    "    burns = burns_t.T\n",
    "    burns.drop(['EGFP','tdTom'],\n",
    "               axis=1,inplace=True)\n",
    "    #-----------------------------#\n",
    "    \n",
    "    \n",
    "    \n",
    "    #--------------------------------------#\n",
    "    ### load Hoa et al. data (GSE135703) ###\n",
    "    hoa_t = pd.read_csv(('GSE135703/'\n",
    "                         'ExpressionMatrix.csv'),\n",
    "                         index_col=0)\n",
    "    \n",
    "    geneVersion_to_mouseName = pd.read_csv(('metaAnalysis/'\n",
    "                                            'refs/geneVersion'\n",
    "                                            '_to_mouseName.csv'),\n",
    "                                            index_col=1)\n",
    "    hoa = hoa_t.T\n",
    "    hoa = hoa.loc[:,[x for x in hoa.columns.values if x in \n",
    "                     geneVersion_to_mouseName.index.values]]\n",
    "    \n",
    "    hoa.columns = [geneVersion_to_mouseName.loc[x,'Gene name'].values[0] if\n",
    "                   type(geneVersion_to_mouseName.loc[x,'Gene name'])!=str\n",
    "                   else geneVersion_to_mouseName.loc[x,'Gene name'] for x in\n",
    "                   hoa.columns.values]\n",
    "    #--------------------------------#\n",
    "    \n",
    "    \n",
    "    \n",
    "    #-----------------------------------#\n",
    "    ### compile support cell metadata ###\n",
    "    print('compiling metadata...')\n",
    "    allCells = np.concatenate((labeled_data.index.values,\n",
    "                               burns.index.values,\n",
    "                               hoa.index.values))\n",
    "    \n",
    "    metadata = pd.DataFrame(index=allCells,\n",
    "                            columns=['dataset',\n",
    "                                     'species',\n",
    "                                     'organ',\n",
    "                                     'type',\n",
    "                                     'subtype'])\n",
    "    \n",
    "    for idx in tqdm(metadata.index.values):\n",
    "    \n",
    "        # lush et al\n",
    "        if idx in labeled_data.index.values:\n",
    "            \n",
    "            metadata.loc[idx,'dataset'] = 'lush et al'\n",
    "            metadata.loc[idx,'species'] = 'D. rerio'\n",
    "            metadata.loc[idx,'organ'] = 'neuromast'\n",
    "            node = labeled_data.loc[idx,'node']\n",
    "            \n",
    "            if node in [7,8,9,14]:\n",
    "                metadata.loc[idx,'type'] = 'sc'\n",
    "                metadata.loc[idx,'subtype'] = 'central sc'\n",
    "                \n",
    "            elif node == 4:\n",
    "                metadata.loc[idx,'type'] = 'sc'\n",
    "                metadata.loc[idx,'subtype'] = 'differentiating sc'\n",
    "                \n",
    "            elif node in [3,10,11]:\n",
    "                metadata.loc[idx,'type'] = 'sc'\n",
    "                metadata.loc[idx,'subtype'] = 'D/V amplifying sc'\n",
    "                \n",
    "            elif node == 13:\n",
    "                metadata.loc[idx,'type'] = 'sc'\n",
    "                metadata.loc[idx,'subtype'] = 'A/P pole sc'\n",
    "                \n",
    "            elif node in [5,6]:\n",
    "                metadata.loc[idx,'type'] = 'mc'\n",
    "            \n",
    "            \n",
    "        # burns et al\n",
    "        if idx in burns.index.values:\n",
    "            \n",
    "            metadata.loc[idx,'dataset'] = 'burns et al'\n",
    "            metadata.loc[idx,'species'] = 'M. musculus'\n",
    "            \n",
    "            if idx in burns_phenoData_utric.index.values:\n",
    "                \n",
    "                metadata.loc[idx,'organ'] = 'utricle'\n",
    "                GroupID = burns_phenoData_utric.loc[idx,'GroupID']\n",
    "                \n",
    "                if GroupID == 'TEC':\n",
    "                    metadata.loc[idx,'type'] = 'tec'\n",
    "                    \n",
    "                elif GroupID == 'SC (i)':\n",
    "                    metadata.loc[idx,'type'] = 'sc'\n",
    "                    metadata.loc[idx,'subtype'] = 'young sc'\n",
    "                    \n",
    "                elif GroupID == 'SC (ii)':\n",
    "                    metadata.loc[idx,'type'] = 'sc'\n",
    "                    metadata.loc[idx,'subtype'] = 'mature sc'\n",
    "                    \n",
    "            elif idx in burns_phenoData_cochl1.index.values:\n",
    "                \n",
    "                metadata.loc[idx,'organ'] = 'corti'\n",
    "                GroupID = burns_phenoData_cochl1.loc[idx,'GroupID']\n",
    "                \n",
    "                if GroupID in ['NSC (i)','NSC (ii)']:\n",
    "                    metadata.loc[idx,'type'] = 'nsc'\n",
    "                    \n",
    "                elif GroupID == 'SC':\n",
    "                    metadata.loc[idx,'type'] = 'sc'\n",
    "                    \n",
    "            elif idx in burns_phenoData_cochl2.index.values:\n",
    "                \n",
    "                metadata.loc[idx,'organ'] = 'corti'\n",
    "                GroupID = burns_phenoData_cochl2.loc[idx,'GroupID']\n",
    "                \n",
    "                if GroupID == 'MedSC':\n",
    "                    metadata.loc[idx,'type'] = 'sc'\n",
    "                    metadata.loc[idx,'subtype'] = 'medial sc'\n",
    "                    \n",
    "                elif GroupID in ['LatSCa','LatSCb']:\n",
    "                    metadata.loc[idx,'type'] = 'sc'\n",
    "                    metadata.loc[idx,'subtype'] = 'lateral sc'\n",
    "    \n",
    "    \n",
    "        # hoa et al\n",
    "        elif idx in hoa.index.values:\n",
    "            \n",
    "            metadata.loc[idx,'dataset'] = 'hoa et al'\n",
    "            metadata.loc[idx,'species'] = 'M. musculus'\n",
    "            metadata.loc[idx,'organ'] = 'corti'\n",
    "            metadata.loc[idx,'type'] = 'sc'\n",
    "    \n",
    "    \n",
    "    # remove empty rows and save metadata \n",
    "    metadata = metadata.loc[metadata.index.values[~metadata['type'].isnull().values],:] \n",
    "    \n",
    "    metadata.to_csv(('metaAnalysis/'\n",
    "                     'datasets/'\n",
    "                     'metadata.csv'))\n",
    "    #-------------------------------#\n",
    "\n",
    "    \n",
    "    \n",
    "    #------------------------------------------#\n",
    "    ### common genes for dataset integration ###                \n",
    "    shared_genes = np.array(list(set(labeled_data.columns.values).intersection(\n",
    "                            set(burns.columns.values),\n",
    "                            set(hoa.columns.values))))\n",
    "    #------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    \n",
    "    #--------------------------#\n",
    "    ### write zebrafish data ###\n",
    "    lush = labeled_data.loc[[idx for idx in labeled_data.index.values if\n",
    "                             idx in metadata.index.values],shared_genes].T\n",
    "    lush = lush.loc[~lush.index.duplicated(keep='first')]\n",
    "    \n",
    "    lush.to_csv(('metaAnalysis/'\n",
    "                 'datasets/'\n",
    "                 'lush.csv'))\n",
    "    #-----------------------#\n",
    "    \n",
    "    \n",
    "    \n",
    "    #----------------------#\n",
    "    ### write mouse data ###\n",
    "    burns = burns.loc[[idx for idx in burns.index.values if \n",
    "                       idx in metadata.index.values],shared_genes].T\n",
    "    burns = burns.loc[~burns.index.duplicated(keep='first')]\n",
    "    \n",
    "    burns.to_csv(('metaAnalysis/'\n",
    "                  'datasets/'\n",
    "                  'burns.csv'))\n",
    "    \n",
    "    hoa = hoa.loc[[idx for idx in hoa.index.values if \n",
    "                   idx in metadata.index.values],shared_genes].T\n",
    "    hoa = hoa.loc[~hoa.index.duplicated(keep='first')]\n",
    "    \n",
    "    hoa.to_csv(('metaAnalysis/'\n",
    "                'datasets/'\n",
    "                'hoa.csv'))\n",
    "    #---------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------#\n",
    "########## UMAP before alignment ##########\n",
    "#-----------------------------------------#\n",
    "\n",
    "\n",
    "#-----------------------------#\n",
    "### additional dependencies ###\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "from sklearn.decomposition import PCA\n",
    "import umap.umap_ as umap\n",
    "#-----------------------#\n",
    "\n",
    "try:\n",
    "    umap_before = pd.read_csv(('metaAnalysis/'\n",
    "                               'embeddings/'\n",
    "                               'umap_before.csv'),\n",
    "                               index_col=0) \n",
    "except:\n",
    "    \n",
    "    #----------#\n",
    "    ### UMAP ###\n",
    "    n_pcs = 100\n",
    "    reducer = umap.UMAP()\n",
    "    \n",
    "    lush = scprep.normalize.library_size_normalize(lush)\n",
    "    lush = scprep.transform.log(lush)\n",
    "    \n",
    "    burns = scprep.normalize.library_size_normalize(burns)\n",
    "    burns = scprep.transform.log(burns)\n",
    "    \n",
    "    hoa = scprep.normalize.library_size_normalize(hoa)\n",
    "    hoa = scprep.transform.log(hoa)\n",
    "    \n",
    "    data_before = np.hstack((lush.values,\n",
    "                             burns.values,\n",
    "                             hoa.values)).T\n",
    "    \n",
    "    pca_before = PCA(n_components=n_pcs\n",
    "                     ).fit_transform(data_before)\n",
    "    \n",
    "    umap_before = reducer.fit_transform(pca_before)\n",
    "    umap_before = pd.DataFrame(umap_before,columns=['UMAP_1',\n",
    "                                                    'UMAP_2'],\n",
    "                               index=np.concatenate(\n",
    "                                   (lush.columns.values,\n",
    "                                    burns.columns.values,\n",
    "                                    hoa.columns.values)))\n",
    "    \n",
    "    umap_before.to_csv(('metaAnalysis/'\n",
    "                        'embeddings/'\n",
    "                        'umap_before.csv'))\n",
    "    #-------------------------------------#\n",
    "\n",
    "\n",
    "    \n",
    "#-------------------------#\n",
    "### dataset identifiers ###\n",
    "lush_cells = metadata.index.values[np.where((metadata['dataset']=='lush et al'))]\n",
    "\n",
    "burns_cells = metadata.index.values[np.where((metadata['dataset']=='burns et al'))]\n",
    "\n",
    "hoa_cells = metadata.index.values[np.where((metadata['dataset']=='hoa et al'))]\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#---------------#\n",
    "### plot UMAP ###\n",
    "sz = 2\n",
    "lw = sz*0.1\n",
    "plt.figure(figsize=(2.5,1.25))\n",
    "\n",
    "lush_plt = plt.scatter(umap_before.loc[lush_cells,'UMAP_1'],\n",
    "                       umap_before.loc[lush_cells,'UMAP_2'],\n",
    "                       c='seagreen',\n",
    "                       edgecolor='k',\n",
    "                       linewidth=lw,\n",
    "                       s=sz)\n",
    "\n",
    "burns_plt = plt.scatter(umap_before.loc[burns_cells,'UMAP_1'],\n",
    "                        umap_before.loc[burns_cells,'UMAP_2'],\n",
    "                        c='indianred',\n",
    "                        edgecolor='k',\n",
    "                        linewidth=lw,\n",
    "                        s=sz)\n",
    "\n",
    "hoa_plt = plt.scatter(umap_before.loc[hoa_cells,'UMAP_1'],\n",
    "                      umap_before.loc[hoa_cells,'UMAP_2'],\n",
    "                      c='goldenrod',\n",
    "                      edgecolor='k',\n",
    "                      linewidth=lw,\n",
    "                      s=sz)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axis('off')\n",
    "\n",
    "lgd = ax.legend([(lush_plt),(burns_plt,hoa_plt)],\n",
    "                [('D. rerio neuromast support \\n'\n",
    "                  '& mantle cells (lush et al.)'),\n",
    "                 ('M. mus. inner ear support \\n'\n",
    "                  'cells (multiple studies)')],\n",
    "                 loc='lower right',\n",
    "                 borderaxespad=0,\n",
    "                 bbox_to_anchor=(1,0),\n",
    "                 fontsize=4,\n",
    "                 frameon=False,\n",
    "                 markerscale=2,\n",
    "                 handler_map=\n",
    "                {tuple:HandlerTuple(\n",
    "                    ndivide=None)})\n",
    "\n",
    "for t in lgd.get_texts():\n",
    "    t.set_ha('center')\n",
    "    t.set_position((400,0))\n",
    "\n",
    "    \n",
    "# axes annotation\n",
    "plt.annotate(s='',xy=(0,0.3),\n",
    "             xytext=(0.15,0),\n",
    "             xycoords=\n",
    "             'axes fraction',\n",
    "             arrowprops=\n",
    "             dict(arrowstyle=('<->,'\n",
    "             'head_width=0.05,'\n",
    "             'head_length=0.1'),\n",
    "             connectionstyle=\n",
    "             ('angle,rad=0,'\n",
    "              'angleA=0,'\n",
    "              'angleB=-90'),\n",
    "             color='k',\n",
    "             linewidth=0.5))\n",
    "\n",
    "plt.text(s='UMAP1',\n",
    "         x=0.065,\n",
    "         y=-0.05,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.text(s='UMAP2',\n",
    "         x=-0.025,\n",
    "         y=0.13,\n",
    "         rotation=90,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.savefig(('metaAnalysis/'\n",
    "             'figures/'\n",
    "             'before.png'),\n",
    "             dpi=dpi)\n",
    "#-------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------#\n",
    "########## UMAP after alignment ##########\n",
    "#----------------------------------------#\n",
    "\n",
    "\n",
    "#------------------------------#\n",
    "### load aligned data from R ###\n",
    "data_after = pd.read_csv(('metaAnalysis/'\n",
    "                          'datasets/'\n",
    "                          'aligned.csv'),\n",
    "                          index_col=0).T\n",
    "\n",
    "data_after['ids'] = [x.replace(\".\",\"-\") for x in \n",
    "                     data_after.index.values]\n",
    "\n",
    "data_after.set_index('ids',\n",
    "                inplace=True)\n",
    "\n",
    "alignment_fts = pd.read_csv(('metaAnalysis/'\n",
    "                             'datasets/'\n",
    "                             'features.csv'),\n",
    "                             index_col=0)\n",
    "#---------------------------------------#\n",
    "\n",
    "\n",
    "try:\n",
    "    umap_after = pd.read_csv(('metaAnalysis/'\n",
    "                              'embeddings/'\n",
    "                              'umap_after.csv'),\n",
    "                              index_col=0) \n",
    "    \n",
    "except:\n",
    "    #----------#\n",
    "    ### UMAP ###\n",
    "    n_pcs = 100\n",
    "    reducer = umap.UMAP()\n",
    "    \n",
    "    pca_after = PCA(n_components=n_pcs).fit_transform(\n",
    "        data_after.loc[:,alignment_fts['anchors@anchor.features'].values])\n",
    "    \n",
    "    umap_after = reducer.fit_transform(pca_after)\n",
    "    umap_after = pd.DataFrame(umap_after,\n",
    "                              columns=['UMAP_1','UMAP_2'],\n",
    "                              index=data_after.index.values)\n",
    "    \n",
    "    umap_after.to_csv(('metaAnalysis/'\n",
    "                       'embeddings/'\n",
    "                       'umap_after.csv'))\n",
    "    #-----------------------------------#\n",
    "\n",
    "\n",
    "    \n",
    "#---------------#    \n",
    "### plot UMAP ###\n",
    "sz = 4\n",
    "lw = sz*0.1\n",
    "plt.figure(figsize=(1.25,1.25))\n",
    "\n",
    "lush_plt = plt.scatter(umap_after.loc[lush_cells,'UMAP_1'],\n",
    "                       umap_after.loc[lush_cells,'UMAP_2'],\n",
    "                       c='seagreen',\n",
    "                       edgecolor='k',\n",
    "                       linewidth=lw,\n",
    "                       s=sz)\n",
    "\n",
    "burns_plt = plt.scatter(umap_after.loc[burns_cells,'UMAP_1'],\n",
    "                        umap_after.loc[burns_cells,'UMAP_2'],\n",
    "                        c='indianred',\n",
    "                        edgecolor='k',\n",
    "                        linewidth=lw,\n",
    "                        s=sz)\n",
    "\n",
    "hoa_plt = plt.scatter(umap_after.loc[hoa_cells,'UMAP_1'],\n",
    "                      umap_after.loc[hoa_cells,'UMAP_2'],\n",
    "                      c='goldenrod',\n",
    "                      edgecolor='k',\n",
    "                      linewidth=lw,\n",
    "                      s=sz)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "# axes annotation\n",
    "plt.annotate(s='',xy=(0,0.3),\n",
    "             xytext=(0.3,0),\n",
    "             xycoords=\n",
    "             'axes fraction',\n",
    "             arrowprops=\n",
    "             dict(arrowstyle=('<->,'\n",
    "             'head_width=0.05,'\n",
    "             'head_length=0.1'),\n",
    "             connectionstyle=\n",
    "             ('angle,rad=0,'\n",
    "              'angleA=0,'\n",
    "              'angleB=-90'),\n",
    "             color='k',\n",
    "             linewidth=0.5))\n",
    "\n",
    "plt.text(s='UMAP1',\n",
    "         x=0.13,\n",
    "         y=-0.05,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.text(s='UMAP2',\n",
    "         x=-0.05,\n",
    "         y=0.13,\n",
    "         rotation=90,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.savefig(('metaAnalysis/'\n",
    "             'figures/'\n",
    "             'after.png'),\n",
    "             dpi=dpi)\n",
    "#-------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------#\n",
    "########## find Gaussian mixture for clustering ##########\n",
    "#--------------------------------------------------------#\n",
    "\n",
    "#-----------------------------#\n",
    "### additional dependencies ###\n",
    "from sklearn import mixture\n",
    "from kneed import KneeLocator\n",
    "#---------------------------#\n",
    "\n",
    "cluster_n = np.arange(1,21)\n",
    "sample_m = np.arange(0,100)\n",
    "\n",
    "try:\n",
    "    bic = pd.read_csv(('metaAnalysis/'\n",
    "                       'results/'\n",
    "                       'bic.csv'),\n",
    "                       index_col=0)\n",
    "    \n",
    "    aic = pd.read_csv(('metaAnalysis/'\n",
    "                       'results/'\n",
    "                       'aic.csv'),\n",
    "                       index_col=0)\n",
    "    \n",
    "except:\n",
    "\n",
    "    #--------------------------------------------------#\n",
    "    ### calculate bic & aic for different n clusters ###\n",
    "    bic = pd.DataFrame(index=sample_m,\n",
    "                       columns=cluster_n)\n",
    "\n",
    "    aic = pd.DataFrame(index=sample_m,\n",
    "                       columns=cluster_n)\n",
    "\n",
    "    for m in tqdm(sample_m):\n",
    "    \n",
    "        for n in cluster_n:\n",
    "    \n",
    "            gm = mixture.GaussianMixture(n_components=n,\n",
    "                                         covariance_type='full'\n",
    "                                         ).fit(umap_after)\n",
    "        \n",
    "            bic.loc[m,n] = gm.bic(umap_after)\n",
    "            aic.loc[m,n] = gm.aic(umap_after)\n",
    "    \n",
    "        # normalize bic & aic for each sampling\n",
    "        bic.loc[m,:] = (bic.loc[m,:]-bic.loc[m,:].min())/(bic.loc[m,:].max()-bic.loc[m,:].min())\n",
    "        aic.loc[m,:] = (aic.loc[m,:]-aic.loc[m,:].min())/(aic.loc[m,:].max()-aic.loc[m,:].min())\n",
    "        \n",
    "        \n",
    "    bic.to_csv(('metaAnalysis/'\n",
    "                'results/'\n",
    "                'bic.csv'))\n",
    "    \n",
    "    aic.to_csv(('metaAnalysis/'\n",
    "                'results/'\n",
    "                'aic.csv'))\n",
    "    #---------------------#\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------#\n",
    "### determine the knees ###\n",
    "bic_knee = KneeLocator(cluster_n,\n",
    "                       bic.mean(axis=0),\n",
    "                       S=1.0,\n",
    "                       curve=\n",
    "                       'convex',\n",
    "                       direction=\n",
    "                       'decreasing')\n",
    "\n",
    "aic_knee = KneeLocator(cluster_n,\n",
    "                       aic.mean(axis=0),\n",
    "                       S=1.0,\n",
    "                       curve=\n",
    "                       'convex',\n",
    "                       direction=\n",
    "                       'decreasing')\n",
    "\n",
    "print('Detected knee at: '+\n",
    "      str(bic_knee.knee)+\n",
    "      ' and '+str(aic_knee.knee))\n",
    "#-------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------#\n",
    "### plot bic & aic ###\n",
    "plt.figure(figsize=(2.5,1.25))\n",
    "\n",
    "plt.plot(cluster_n,\n",
    "         bic.mean(axis=0),\n",
    "         linewidth=1,\n",
    "         marker='.',\n",
    "         markersize=4,\n",
    "         c='tab:blue',\n",
    "         label='BIC')\n",
    "\n",
    "plt.plot(cluster_n,\n",
    "         aic.mean(axis=0),\n",
    "         linewidth=1,\n",
    "         marker='.',\n",
    "         markersize=4,\n",
    "         c='tab:red',\n",
    "         label='AIC')\n",
    "\n",
    "plt.legend(fontsize=5,\n",
    "           frameon=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "b,t = ax.get_ylim()\n",
    "\n",
    "knee = 3\n",
    "print('Knee plotted at: '+str(knee))\n",
    "plt.vlines(knee,b,t,\n",
    "           color='k',\n",
    "           linestyle=\n",
    "           'dotted',\n",
    "           linewidth=1)\n",
    "\n",
    "ax.set_ylim(b,t)\n",
    "plt.xticks(cluster_n[::2])\n",
    "\n",
    "ax.set_xlabel('Clusters',\n",
    "              fontsize=5)\n",
    "\n",
    "ax.set_ylabel('Normalized Score',\n",
    "              fontsize=5)\n",
    "\n",
    "ax.tick_params(axis='both',\n",
    "               which='major',\n",
    "               labelsize=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(('metaAnalysis/'\n",
    "             'figures/'\n",
    "             'crit.png'),\n",
    "             dpi=dpi)\n",
    "#-------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------#\n",
    "########## plot by cluster ##########\n",
    "#-----------------------------------#\n",
    "\n",
    "\n",
    "try:\n",
    "    labels_df = pd.read_csv(('metaAnalysis/'\n",
    "                             'embeddings/'\n",
    "                             'labels.csv'),\n",
    "                             index_col=0)\n",
    "    \n",
    "except:\n",
    "    \n",
    "    #----------------------------------------------------#\n",
    "    ### compute Gaussians and assign cells to clusters ###\n",
    "    gm = mixture.GaussianMixture(n_components=knee,\n",
    "                                 covariance_type='full'\n",
    "                                 ).fit(umap_after)\n",
    "\n",
    "    labels_df = pd.DataFrame(gm.predict(umap_after),\n",
    "                             index=umap_after.index.values,\n",
    "                             columns=['gmm_cluster'])\n",
    "    \n",
    "    labels_df.to_csv(('metaAnalysis/'\n",
    "                      'embeddings/'\n",
    "                      'labels.csv'))\n",
    "    #------------------------------#\n",
    "    \n",
    "    \n",
    "    \n",
    "#-------------------------------#\n",
    "### identifiers by cluster ###\n",
    "clus0 = metadata.index.values[np.where((labels_df['gmm_cluster']==0))]\n",
    "clus1 = metadata.index.values[np.where((labels_df['gmm_cluster']==1))]\n",
    "clus2 = metadata.index.values[np.where((labels_df['gmm_cluster']==2))]\n",
    "#--------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#-----------------#\n",
    "### plot figure ###\n",
    "sz = 4\n",
    "lw = sz*0.1\n",
    "plt.figure(figsize=(1.25,1.25))\n",
    "\n",
    "plt.scatter(umap_after.loc[clus0,'UMAP_1'],\n",
    "            umap_after.loc[clus0,'UMAP_2'],\n",
    "            label='0',\n",
    "            c='slateblue',\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            s=sz)\n",
    "\n",
    "plt.scatter(umap_after.loc[clus1,'UMAP_1'],\n",
    "            umap_after.loc[clus1,'UMAP_2'],\n",
    "            label='1',\n",
    "            c='cadetblue',\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            s=sz)\n",
    "\n",
    "plt.scatter(umap_after.loc[clus2,'UMAP_1'],\n",
    "            umap_after.loc[clus2,'UMAP_2'],\n",
    "            label='2',\n",
    "            c='sandybrown',\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            s=sz)\n",
    "\n",
    "lgd = plt.legend(fontsize=4,\n",
    "                 frameon=False,\n",
    "                 markerscale=1.5,\n",
    "                 loc='lower right',\n",
    "                 borderaxespad=0,\n",
    "                 bbox_to_anchor=(1,0))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axis('off')\n",
    "\n",
    "# axes annotation\n",
    "plt.annotate(s='',xy=(0,0.3),\n",
    "             xytext=(0.3,0),\n",
    "             xycoords=\n",
    "             'axes fraction',\n",
    "             arrowprops=\n",
    "             dict(arrowstyle=('<->,'\n",
    "             'head_width=0.05,'\n",
    "             'head_length=0.1'),\n",
    "             connectionstyle=\n",
    "             ('angle,rad=0,'\n",
    "              'angleA=0,'\n",
    "              'angleB=-90'),\n",
    "             color='k',\n",
    "             linewidth=0.5))\n",
    "\n",
    "plt.text(s='UMAP1',\n",
    "         x=0.13,\n",
    "         y=-0.05,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.text(s='UMAP2',\n",
    "         x=-0.05,\n",
    "         y=0.13,\n",
    "         rotation=90,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.savefig(('metaAnalysis/'\n",
    "             'figures/'\n",
    "             'cluster.png'),\n",
    "             dpi=dpi)\n",
    "#-------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------#\n",
    "########## plot by cell cycle ##########\n",
    "#--------------------------------------#\n",
    "\n",
    "\n",
    "#----------------------------#\n",
    "### load cell cycle labels ###\n",
    "phases = pd.read_csv(('metaAnalysis/'\n",
    "                      'datasets/'\n",
    "                      'phases.csv'),\n",
    "                      index_col=0)\n",
    "\n",
    "phases['ids'] = data_after.index.values\n",
    "\n",
    "phases.set_index('ids',\n",
    "                 inplace=True)\n",
    "\n",
    "phases.rename({phases.columns.values[0]:'phase'},\n",
    "              axis=1,\n",
    "              inplace=True)\n",
    "#-------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------#\n",
    "### identifiers by cell cycle ###\n",
    "g1 = metadata.index.values[np.where((phases['phase']=='G1'))]\n",
    "s = metadata.index.values[np.where((phases['phase']=='S'))]\n",
    "g2m = metadata.index.values[np.where((phases['phase']=='G2M'))]\n",
    "#-------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#-----------------#\n",
    "### plot figure ###\n",
    "sz = 4\n",
    "lw = sz*0.1\n",
    "plt.figure(figsize=(1.25,1.25))\n",
    "\n",
    "c=['slategray',\n",
    "   'royalblue',\n",
    "   'orchid']\n",
    "\n",
    "for idx in metadata.index.values:\n",
    "    \n",
    "    phase = phases.loc[idx,'phase']\n",
    "    \n",
    "    if phase == 'G1':\n",
    "\n",
    "        plt.scatter(umap_after.loc[idx,'UMAP_1'],\n",
    "            umap_after.loc[idx,'UMAP_2'],\n",
    "            c=c[0],\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            s=sz)\n",
    "        \n",
    "    elif phase == 'S':\n",
    "\n",
    "        plt.scatter(umap_after.loc[idx,'UMAP_1'],\n",
    "            umap_after.loc[idx,'UMAP_2'],\n",
    "            c=c[1],\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            s=sz)\n",
    "        \n",
    "    else:\n",
    "\n",
    "        plt.scatter(umap_after.loc[idx,'UMAP_1'],\n",
    "            umap_after.loc[idx,'UMAP_2'],\n",
    "            c=c[2],\n",
    "            edgecolor='k',\n",
    "            linewidth=lw,\n",
    "            s=sz)\n",
    "        \n",
    "        \n",
    "g1_lgd = plt.scatter([],[],\n",
    "                     c=c[0],\n",
    "                     label='G1',\n",
    "                     edgecolor='k',\n",
    "                     linewidth=lw,\n",
    "                     s=sz)\n",
    "\n",
    "s_lgd = plt.scatter([],[],\n",
    "                    c=c[1],\n",
    "                    label='S',\n",
    "                    edgecolor='k',\n",
    "                    linewidth=lw,\n",
    "                    s=sz)\n",
    "\n",
    "g2m_lgd = plt.scatter([],[],\n",
    "                      c=c[2],\n",
    "                      label='G2M',\n",
    "                      edgecolor='k',\n",
    "                      linewidth=lw,\n",
    "                      s=sz)\n",
    "\n",
    "\n",
    "lgd = plt.legend(handles=[g1_lgd,\n",
    "                          s_lgd,\n",
    "                          g2m_lgd],\n",
    "                 fontsize=4,\n",
    "                 frameon=False,\n",
    "                 markerscale=1.5,\n",
    "                 loc='lower right',\n",
    "                 borderaxespad=0,\n",
    "                 bbox_to_anchor=(1,0))\n",
    "\n",
    "for t in lgd.get_texts():\n",
    "    t.set_ha('center')\n",
    "    t.set_position((50,0))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axis('off')\n",
    "\n",
    "# axes annotation\n",
    "plt.annotate(s='',xy=(0,0.3),\n",
    "             xytext=(0.3,0),\n",
    "             xycoords=\n",
    "             'axes fraction',\n",
    "             arrowprops=\n",
    "             dict(arrowstyle=('<->,'\n",
    "             'head_width=0.05,'\n",
    "             'head_length=0.1'),\n",
    "             connectionstyle=\n",
    "             ('angle,rad=0,'\n",
    "              'angleA=0,'\n",
    "              'angleB=-90'),\n",
    "             color='k',\n",
    "             linewidth=0.5))\n",
    "\n",
    "plt.text(s='UMAP1',\n",
    "         x=0.13,\n",
    "         y=-0.05,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.text(s='UMAP2',\n",
    "         x=-0.05,\n",
    "         y=0.13,\n",
    "         rotation=90,\n",
    "         va='center',\n",
    "         ha='center',\n",
    "         color='k',\n",
    "         fontsize=4,\n",
    "         transform=\n",
    "         ax.transAxes)\n",
    "\n",
    "plt.savefig(('metaAnalysis/'\n",
    "             'figures/'\n",
    "             'cycle.png'),\n",
    "             dpi=dpi)\n",
    "#-------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# med_lat = data_before.loc[data_before.index.values[np.where((metadata['organ']=='corti')&\n",
    "#                          (metadata['type']=='sc')&(metadata['dataset']=='hoa et al'))],\n",
    "#                           ['Plp1','Plp2','Prox1','Cdh4','Sparcl1','Cntn1','Fabp7','Gjb2','Cdh1',\n",
    "#                            'Anxa5','Fabp7','Matn4','Emid1','Npy','Ppp1r2','Serpine2','Hes5',\n",
    "#                            'S100a1','Lfng','Egfl6','Nupr1']]\n",
    "\n",
    "# med_lat_pca = sklearn.decomposition.PCA(n_components=4).fit_transform(med_lat)\n",
    "\n",
    "# reducer = umap.UMAP()\n",
    "# med_lat_umap = reducer.fit_transform(med_lat_pca)\n",
    "\n",
    "# plt.scatter(med_lat_umap[:,0],med_lat_umap[:,1],s=5,edgecolor='k')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #----------------------------------------------------#\n",
    "# ########## cell types in segregated cluster ##########\n",
    "# #----------------------------------------------------#\n",
    "\n",
    "\n",
    "# #---------------------------------------#\n",
    "# ### concatenate datasets (raw counts) ###\n",
    "# data_before = pd.DataFrame(np.hstack((lush.values,\n",
    "#                                       burns.values,\n",
    "#                                       hoa.values)).T,\n",
    "                           \n",
    "#                            columns=lush.index.values,\n",
    "#                            index=np.concatenate(\n",
    "#                                (lush.columns.values,\n",
    "#                                 burns.columns.values,\n",
    "#                                 hoa.columns.values)))\n",
    "# #---------------------------------------------------#\n",
    "\n",
    "\n",
    "# #------------------------------------------------#\n",
    "# ### cell type counts in the segregated cluster ###\n",
    "\n",
    "# dvsc = np.sum((labels_df['gmm_cluster']==1)&\n",
    "#               (metadata['subtype']=='D/V amplifying sc'))\n",
    "\n",
    "# diffsc = np.sum((labels_df['gmm_cluster']==1)&\n",
    "#                 (metadata['subtype']=='differentiating sc'))\n",
    "\n",
    "# iphc_bc = np.sum((labels_df['gmm_cluster']==1)&\n",
    "#                  (metadata['organ']=='corti')&\n",
    "#                  (metadata['type']=='sc')&\n",
    "#                  (data_before[['Plp1','Plp2']].sum(axis=1)>0))\n",
    "\n",
    "# fish_other = np.sum((labels_df['gmm_cluster']==1)&\n",
    "#                     (metadata['species']=='D. rerio')&\n",
    "#                     (metadata['subtype']!='D/V amplifying sc')&\n",
    "#                     (metadata['subtype']!='differentiating sc'))\n",
    "\n",
    "# mouse_other = np.sum((labels_df['gmm_cluster']==1))-\\\n",
    "#                       dvsc-diffsc-iphc_bc-fish_other     \n",
    "# #--------------------------------------------------#\n",
    "\n",
    "\n",
    "# #-----------------#\n",
    "# ### plot figure ###\n",
    "# _,(a0, a1) = plt.subplots(2,1,gridspec_kw=\n",
    "#                           {'height_ratios':[8, 1]},\n",
    "#                           figsize=(1.25,1.25))\n",
    "\n",
    "# pie = a0.pie([dvsc,\n",
    "#               diffsc,\n",
    "#               fish_other,\n",
    "#               iphc_bc,\n",
    "#               mouse_other],\n",
    "#              colors=\n",
    "#              ['dimgray',\n",
    "#               'darkgray',\n",
    "#               'lightgray',\n",
    "#               'whitesmoke',\n",
    "#               'black'])\n",
    "\n",
    "# a1.axis(\"off\") \n",
    "# a1.legend(handles=pie[0],\n",
    "#            labels=[\"D/V sc's (D. rerio)\",\n",
    "#                    \"diff. sc's (D. rerio)\",\n",
    "#                    'Other (D. rerio)',\n",
    "#                    \"IPhC's & BC's (M. mus.)\",\n",
    "#                    'Other (M. mus.)'],\n",
    "#           loc='center',\n",
    "#           frameon=False,\n",
    "#           fontsize=4)\n",
    "\n",
    "# plt.savefig(('metaAnalysis/'\n",
    "#              'figures/'\n",
    "#              'type.png'),\n",
    "#             dpi=dpi)\n",
    "# #------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT LOOKS LIKE DVSCs IN CLUSTER 1 ARE CYCLING MORE THAN OTHER DVSCs? HOW?\n",
    "\n",
    "clus1 = metadata.index.values[np.where((labels_df['gmm_cluster']==1)&\n",
    "                                       (phases['phase']!='G1')&\n",
    "                                       (metadata['subtype']=='D/V amplifying sc'))]\n",
    "\n",
    "clus02 = metadata.index.values[np.where((labels_df['gmm_cluster']!=1)&\n",
    "                                        (phases['phase']!='G1')&\n",
    "                                        (metadata['subtype']=='D/V amplifying sc'))]\n",
    "\n",
    "ids = np.concatenate((clus1,clus02))\n",
    "\n",
    "\n",
    "dds = deseq.DESeqDataSetFromMatrix(countData=data_before.loc[ids,:].values.T+1,\n",
    "                                   colData=robjects.DataFrame({'label':robjects.StrVector(\n",
    "                                   ['clus1' if idx in clus1 else 'clus02' for idx in ids])}),\n",
    "                                   design=Formula('~ label'))\n",
    "dds = deseq.DESeq(dds)\n",
    "\n",
    "res = deseq.results(dds)\n",
    "\n",
    "res_df = pd.DataFrame(index=data_before.columns.values)\n",
    "res_df['P.Value'] = dollar(res,'pvalue')\n",
    "res_df['adj.P.Val'] = dollar(res,'padj')\n",
    "res_df['logFC'] = dollar(res,'log2FoldChange')\n",
    "\n",
    "res_df.sort_values('logFC',\n",
    "                   ascending=False,\n",
    "                   inplace=True)\n",
    "\n",
    "print(res_df.head(20))\n",
    "print(res_df.tail(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib_venn import venn2, venn3\n",
    "\n",
    "#------------------\n",
    "### identifiers for hoa et al\n",
    "clus1_s = metadata.index.values[np.where((metadata['dataset']=='hoa et al')&\n",
    "                                         (labels_df['gmm_cluster']==1)&\n",
    "                                         (phases['phase']=='S'))]\n",
    "\n",
    "clus1_g2m = metadata.index.values[np.where((metadata['dataset']=='hoa et al')&\n",
    "                                           (labels_df['gmm_cluster']==1)&\n",
    "                                           (phases['phase']=='G2M'))]\n",
    "\n",
    "clus02 = metadata.index.values[np.where((metadata['dataset']=='hoa et al')&\n",
    "                                        (labels_df['gmm_cluster']!=1))]\n",
    "\n",
    "hoa_ids = np.concatenate((clus1_s,\n",
    "                          clus1_g2m,\n",
    "                          clus02))\n",
    "#-------------\n",
    "\n",
    "\n",
    "\n",
    "# # deseq2\n",
    "# dds = deseq.DESeqDataSetFromMatrix(countData=data_before.loc[hoa_ids,:].values.T+1,\n",
    "#                                    colData=robjects.DataFrame({'label':robjects.StrVector(\n",
    "#                                    ['clus1_s' if idx in clus1_s else 'clus1_g2m' if idx in \n",
    "#                                     clus1_g2m else 'clus02' for idx in hoa_ids])}),\n",
    "#                                    design=Formula('~ label'))\n",
    "# dds = deseq.DESeq(dds)\n",
    "\n",
    "# hoa_s = deseq.results(dds,contrast=robjects.StrVector(\n",
    "#                       ['label','clus02','clus1_s']))\n",
    "\n",
    "# hoa_g2m = deseq.results(dds,contrast=robjects.StrVector(\n",
    "#                         ['label','clus1_s','clus1_g2m']))\n",
    "\n",
    "# de_hoa = pd.DataFrame(index=data_before.columns.values)\n",
    "# de_hoa['s.P.Value'] = dollar(hoa_s,'pvalue')\n",
    "# de_hoa['s.adj.P.Val'] = dollar(hoa_s,'padj')\n",
    "# de_hoa['s.logFC'] = dollar(hoa_s,'log2FoldChange')\n",
    "# de_hoa['g2m.P.Value'] = dollar(hoa_g2m,'pvalue')\n",
    "# de_hoa['g2m.adj.P.Val'] = dollar(hoa_g2m,'padj')\n",
    "# de_hoa['g2m.logFC'] = dollar(hoa_g2m,'log2FoldChange')\n",
    "\n",
    "\n",
    "upreg_s = de_hoa.index.values[np.where((de_hoa['s.logFC']>1.25)&\n",
    "                                       (de_hoa['s.adj.P.Val']<0.05))]\n",
    "\n",
    "downreg_s = de_hoa.index.values[np.where((de_hoa['s.logFC']<-1.25)&\n",
    "                                         (de_hoa['s.adj.P.Val']<0.05))]\n",
    "\n",
    "upreg_g2m = de_hoa.index.values[np.where((de_hoa['g2m.logFC']>1.25)&\n",
    "                                         (de_hoa['g2m.adj.P.Val']<0.05))]\n",
    "\n",
    "downreg_g2m = de_hoa.index.values[np.where((de_hoa['g2m.logFC']<-1.25)&\n",
    "                                           (de_hoa['g2m.adj.P.Val']<0.05))]\n",
    "\n",
    "plt.figure(figsize=(2.5,2.5))\n",
    "venn3([set(upreg_s),set(upreg_g2m),set(downreg_g2m)])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(2.5,2.5))\n",
    "venn3([set(downreg_s),set(upreg_g2m),set(downreg_g2m)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DE comparison (amplifying S) ##\n",
    "\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "# cell IDs\n",
    "hoa_ampS = metadata.index.values[\\\n",
    "                np.where(amplifying&\n",
    "                (phases['phase']=='S')&\n",
    "                (metadata['dataset']==\n",
    "                 'hoa et al'))]\n",
    "\n",
    "hoa_not = metadata.index.values[\\\n",
    "            np.where(~amplifying&\n",
    "            (metadata['dataset']==\n",
    "             'hoa et al'))]\n",
    "\n",
    "lush_ampS = metadata.index.values[\\\n",
    "                 np.where(amplifying&\n",
    "                 (phases['phase']=='S')&\n",
    "                 (metadata['dataset']==\n",
    "                  'lush et al'))]\n",
    "\n",
    "lush_not = metadata.index.values[\\\n",
    "             np.where(~amplifying&\n",
    "             (metadata['dataset']==\n",
    "              'lush et al'))]\n",
    "\n",
    "hoa_s = np.concatenate((hoa_ampS,\n",
    "                        hoa_not))\n",
    "\n",
    "lush_s = np.concatenate((lush_ampS,\n",
    "                         lush_not))\n",
    "\n",
    "\n",
    "try:\n",
    "    de_hoaS = pd.read_csv(('metaAnalysis/',\n",
    "                          'results/',\n",
    "                          'hoa_de_s.csv'),\n",
    "                          index_col=0)\n",
    "    \n",
    "    de_lushS = pd.read_csv(('metaAnalysis/',\n",
    "                           'results/',\n",
    "                           'lush_de_s.csv'),\n",
    "                           index_col=0)\n",
    "    \n",
    "except:\n",
    "    # hoa amp S vs ~amp (deseq2)\n",
    "    dds = deseq.DESeqDataSetFromMatrix(countData=\n",
    "                data_before.loc[hoa_s,:].values.T+1,\n",
    "                colData=robjects.DataFrame(\\\n",
    "                {'label':robjects.IntVector(\\\n",
    "                [1 if idx in hoa_ampS else 0\\\n",
    "                         for idx in hoa_s])}),\n",
    "                    design=Formula('~ label'))\n",
    "\n",
    "    dds = deseq.DESeq(dds)\n",
    "    ds_res = deseq.results(dds)\n",
    "\n",
    "    de_hoaS = pd.DataFrame(index=\n",
    "                data_before.columns.values)\n",
    "\n",
    "    de_hoaS['P.Value'] = dollar(ds_res,\n",
    "                                'pvalue')\n",
    "\n",
    "    de_hoaS['adj.P.Val'] = dollar(ds_res,\n",
    "                                  'padj')\n",
    "\n",
    "    de_hoaS['logFC'] = dollar(ds_res,\n",
    "                              'log2FoldChange')\n",
    "\n",
    "    de_hoaS.sort_values('logFC',\n",
    "                        ascending=False,\n",
    "                        inplace=True)\n",
    "\n",
    "    de_hoaS.to_csv(('metaAnalysis/',\n",
    "                    'results/',\n",
    "                    'hoa_de_s.csv'))\n",
    "\n",
    "\n",
    "\n",
    "    # lush amp S vs ~amp (deseq2)\n",
    "    dds = deseq.DESeqDataSetFromMatrix(countData=\n",
    "                data_before.loc[lush_s,:].values.T+1,\n",
    "                colData=robjects.DataFrame(\\\n",
    "                {'label':robjects.IntVector(\\\n",
    "                [1 if idx in lush_ampS else 0\\\n",
    "                         for idx in lush_s])}),\n",
    "                    design=Formula('~ label'))\n",
    "\n",
    "    dds = deseq.DESeq(dds)\n",
    "    ds_res = deseq.results(dds)\n",
    "\n",
    "    de_lushS = pd.DataFrame(index=\n",
    "                 data_before.columns.values)\n",
    "\n",
    "    de_lushS['P.Value'] = dollar(ds_res,\n",
    "                                 'pvalue')\n",
    "\n",
    "    de_lushS['adj.P.Val'] = dollar(ds_res,\n",
    "                                   'padj')\n",
    "\n",
    "    de_lushS['logFC'] = dollar(ds_res,\n",
    "                               'log2FoldChange')\n",
    "\n",
    "    de_lushS.sort_values('logFC',\n",
    "                         ascending=False,\n",
    "                         inplace=True)\n",
    "\n",
    "    de_lushS.to_csv(('metaAnalysis/',\n",
    "                     'results/',\n",
    "                     'lush_de_s.csv'))\n",
    "\n",
    "\n",
    "\n",
    "pval = 0.05\n",
    "thresh = 1.25\n",
    "\n",
    "deg_hoaS = de_hoaS.index.values[\\\n",
    "             np.where((de_hoaS['adj.P.Val']<pval)&\n",
    "             (de_hoaS['logFC'].abs()>np.log2(thresh)))]\n",
    "\n",
    "deg_lushS = de_lushS.index.values[\\\n",
    "               np.where((de_lushS['adj.P.Val']<pval)&\n",
    "               (de_lushS['logFC'].abs()>np.log2(thresh)))]\n",
    "\n",
    "\n",
    "# plot venn diagram\n",
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "venn2([set(deg_hoaS),\n",
    "       set(deg_lushS)],\n",
    "      ('adult M. mus. \\n(hoa et al.)',\n",
    "       'D. rerio \\n(lush et al.)'),\n",
    "      set_colors=('teal',\n",
    "                  'palevioletred'),\n",
    "      alpha=1)\n",
    "\n",
    "plt.title('DE Genes'+\n",
    "          '\\nAmplifying S Phase')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(('metaAnalysis/'\n",
    "             'figures/'\n",
    "             'de_s.png'),\n",
    "             dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GO comparison (amplifying S) ##\n",
    "\n",
    "\n",
    "# enriched TF-gene co-ocurrence terms (Enrichr)\n",
    "enr = gp.enrichr(gene_list=list(deg_hoaS),\n",
    "                 background=list(data_after.columns.values),\n",
    "                 description='hoaS',organism='Mouse',\n",
    "                 gene_sets='Enrichr_Submissions_TF-Gene_Coocurrence',\n",
    "                 outdir='metaAnalysis/gseapy/hoaS/',\n",
    "                 cutoff=1,no_plot=True)\n",
    "\n",
    "enr_hoaS = pd.DataFrame(\\\n",
    "                enr.results).sort_values(\\\n",
    "                'Combined Score',ascending=False)\n",
    "\n",
    "enr_hoaS.to_csv('metaAnalysis/'+\n",
    "                'results/'+\n",
    "                'hoa_go_s.csv')\n",
    "\n",
    "\n",
    "\n",
    "enr = gp.enrichr(gene_list=list(deg_lushS),\n",
    "                 background=list(data_after.columns.values),\n",
    "                 description='lushS',organism='Mouse',\n",
    "                 gene_sets='Enrichr_Submissions_TF-Gene_Coocurrence',\n",
    "                 outdir='metaAnalysis/gseapy/lushS/',\n",
    "                 cutoff=1,no_plot=True)\n",
    "\n",
    "enr_lushS = pd.DataFrame(\\\n",
    "                enr.results).sort_values(\\\n",
    "                'Combined Score',ascending=False)\n",
    "\n",
    "enr_lushS.to_csv('metaAnalysis/'+\n",
    "                 'results/'+\n",
    "                 'lush_go_s.csv')\n",
    "\n",
    "\n",
    "# enriched terms\n",
    "hoa_cut = 30                # knee\n",
    "# plt.figure(figsize=(3,2))\n",
    "# plt.scatter(np.arange(enr_hoaS.shape[0]),\n",
    "#             enr_hoaS['Combined Score'],\n",
    "#             c='k',s=2)\n",
    "# ax = plt.gca()\n",
    "# l,r = ax.get_xlim()\n",
    "# plt.hlines(hoa_cut,l,r,\n",
    "#            color='r')\n",
    "# ax.set_xlim(l,r)\n",
    "# plt.show()\n",
    "\n",
    "hoaS_terms = enr_hoaS.loc[enr_hoaS.index.values[\\\n",
    "                np.where(enr_hoaS['Combined Score']>\n",
    "                                         hoa_cut)],:]\n",
    "\n",
    "\n",
    "lush_cut = 200              # knee\n",
    "# plt.figure(figsize=(3,2))\n",
    "# plt.scatter(np.arange(enr_lushS.shape[0]),\n",
    "#             enr_lushS['Combined Score'],\n",
    "#             c='k',s=2)\n",
    "# ax = plt.gca()\n",
    "# l,r = ax.get_xlim()\n",
    "# plt.hlines(lush_cut,l,r,\n",
    "#            color='r')\n",
    "# ax.set_xlim(l,r)\n",
    "# plt.show()\n",
    "\n",
    "lushS_terms = enr_lushS.loc[enr_lushS.index.values[\\\n",
    "                np.where(enr_lushS['Combined Score']>\n",
    "                                         lush_cut)],:]\n",
    "\n",
    "\n",
    "# plot venn diagram\n",
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "venn2([set(hoaS_terms['Term']),\n",
    "       set(lushS_terms['Term'])],\n",
    "      ('adult M. mus. \\n(hoa et al.)',\n",
    "       'D. rerio \\n(lush et al.)'),\n",
    "      set_colors=('teal',\n",
    "                  'palevioletred'),\n",
    "      alpha=1)\n",
    "\n",
    "plt.title('TF-Gene Enriched GO Terms'+\n",
    "          '\\nAmplifying S Phase')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(('metaAnalysis/'\n",
    "             'figures/'\n",
    "             'go_s.png'),\n",
    "             dpi=300)\n",
    "\n",
    "# print zebrafish only terms\n",
    "print('Zebrafish-only terms:')\n",
    "for term in lushS_terms['Term']:\n",
    "    if term not in hoaS_terms['Term'].values:\n",
    "        print(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DE comparison (amplifying G2M) ##\n",
    "\n",
    "\n",
    "# cell IDs\n",
    "hoa_ampG2M = metadata.index.values[\\\n",
    "                  np.where(amplifying&\n",
    "                  (phases['phase']=='G2M')&\n",
    "                  (metadata['dataset']==\n",
    "                   'hoa et al'))]\n",
    "\n",
    "lush_ampG2M = metadata.index.values[\\\n",
    "                   np.where(amplifying&\n",
    "                   (phases['phase']=='G2M')&\n",
    "                   (metadata['dataset']==\n",
    "                    'lush et al'))]\n",
    "\n",
    "hoa_g2m = np.concatenate((hoa_ampS,\n",
    "                          hoa_ampG2M,\n",
    "                          hoa_not))\n",
    "\n",
    "lush_g2m = np.concatenate((lush_ampS,\n",
    "                           lush_ampG2M,\n",
    "                           lush_not))\n",
    "\n",
    "\n",
    "try:\n",
    "    de_hoaG2M = pd.read_csv('metaAnalysis/'+\n",
    "                            'results/'+\n",
    "                            'hoa_de_g2m.csv',\n",
    "                            index_col=0)\n",
    "    \n",
    "    de_lushG2M = pd.read_csv('metaAnalysis/'+\n",
    "                             'results/'+\n",
    "                             'lush_de_g2m.csv',\n",
    "                             index_col=0)\n",
    "    \n",
    "except:\n",
    "    # hoa amp G2M vs amp S + ~amp (deseq2)\n",
    "    dds = deseq.DESeqDataSetFromMatrix(countData=\n",
    "                data_before.loc[hoa_g2m,:].values.T+1,\n",
    "                colData=robjects.DataFrame(\\\n",
    "                {'label':robjects.IntVector(\\\n",
    "                [1 if idx in hoa_ampG2M else 0\\\n",
    "                         for idx in hoa_g2m])}),\n",
    "                    design=Formula('~ label'))\n",
    "\n",
    "    dds = deseq.DESeq(dds)\n",
    "    ds_res = deseq.results(dds)\n",
    "    \n",
    "    de_hoaG2M = pd.DataFrame(index=\n",
    "                  data_before.columns.values)\n",
    "\n",
    "    de_hoaG2M['P.Value'] = dollar(ds_res,\n",
    "                                  'pvalue')\n",
    "\n",
    "    de_hoaG2M['adj.P.Val'] = dollar(ds_res,\n",
    "                                    'padj')\n",
    "\n",
    "    de_hoaG2M['logFC'] = dollar(ds_res,\n",
    "                                'log2FoldChange')\n",
    "\n",
    "    de_hoaG2M.sort_values('logFC',\n",
    "                          ascending=False,\n",
    "                          inplace=True)\n",
    "\n",
    "    de_hoaG2M.to_csv(('metaAnalysis/',\n",
    "                      'results/',\n",
    "                      'hoa_de_g2m.csv'))\n",
    "\n",
    "\n",
    "\n",
    "    # lush amp G2M vs amp S + ~amp (deseq2)\n",
    "    dds = deseq.DESeqDataSetFromMatrix(countData=\n",
    "                data_before.loc[lush_g2m,:].values.T+1,\n",
    "                colData=robjects.DataFrame(\\\n",
    "                {'label':robjects.IntVector(\\\n",
    "                [1 if idx in lush_ampG2M else 0\\\n",
    "                         for idx in lush_g2m])}),\n",
    "                      design=Formula('~ label'))\n",
    "\n",
    "    dds = deseq.DESeq(dds)\n",
    "    ds_res = deseq.results(dds)\n",
    "    \n",
    "    de_lushG2M = pd.DataFrame(index=\n",
    "                   data_before.columns.values)\n",
    "\n",
    "    de_lushG2M['P.Value'] = dollar(ds_res,\n",
    "                                   'pvalue')\n",
    "\n",
    "    de_lushG2M['adj.P.Val'] = dollar(ds_res,\n",
    "                                     'padj')\n",
    "\n",
    "    de_lushG2M['logFC'] = dollar(ds_res,\n",
    "                                 'log2FoldChange')\n",
    "\n",
    "    de_lushG2M.sort_values('logFC',\n",
    "                           ascending=False,\n",
    "                           inplace=True)\n",
    "\n",
    "    de_lushG2M.to_csv(('metaAnalysis/',\n",
    "                       'results/',\n",
    "                       'lush_de_g2m.csv'))\n",
    "\n",
    "\n",
    "\n",
    "pval = 0.05\n",
    "thresh = 1.25\n",
    "\n",
    "deg_hoaG2M = de_hoaG2M.index.values[\\\n",
    "                np.where((de_hoaG2M['adj.P.Val']<pval)&\n",
    "                (de_hoaG2M['logFC'].abs()>np.log2(thresh)))]\n",
    "\n",
    "deg_lushG2M = de_lushG2M.index.values[\\\n",
    "                  np.where((de_lushG2M['adj.P.Val']<pval)&\n",
    "                  (de_lushG2M['logFC'].abs()>np.log2(thresh)))]\n",
    "\n",
    "\n",
    "# plot venn diagram\n",
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "venn2([set(deg_hoaG2M),\n",
    "       set(deg_lushG2M)],\n",
    "      ('adult M. mus. \\n(hoa et al.)',\n",
    "       'D. rerio \\n(lush et al.)'),\n",
    "      set_colors=('teal',\n",
    "                  'palevioletred'),\n",
    "      alpha=1)\n",
    "\n",
    "plt.title('DE Genes'+\n",
    "          '\\nAmplifying G2M Phase')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(('metaAnalysis/'\n",
    "             'figures/'\n",
    "             'de_g2m.png'),\n",
    "             dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "limma = importr('limma')\n",
    "\n",
    "# cell IDs\n",
    "dvsc_s = metadata.index.values[\\\n",
    "            np.where(amplifying&\n",
    "             (phases['phase']=='S')&\n",
    "             (metadata['subtype']==\n",
    "              'D/V amplifying sc'))]\n",
    "\n",
    "corti_s = metadata.index.values[\\\n",
    "            np.where(amplifying&\n",
    "             (phases['phase']=='S')&\n",
    "             (metadata['dataset']==\n",
    "                      'hoa et al')&\n",
    "             (metadata['organ']==\n",
    "                          'corti')&\n",
    "             (metadata['type']=='sc'))]\n",
    "\n",
    "# dvsc_g2m = metadata.index.values[np.where(amplifying&\n",
    "#                                  (phases['phase']=='G2M')&\n",
    "#                                  (metadata['subtype']==\n",
    "#                                   'D/V amplifying sc'))]\n",
    "\n",
    "# corti_g2m = metadata.index.values[np.where(amplifying&\n",
    "#                                   (phases['phase']=='G2M')&\n",
    "#                                   (metadata['organ']=='corti')&\n",
    "#                                   (metadata['type']=='sc'))]\n",
    "                                   \n",
    "S = np.concatenate((dvsc_s,\n",
    "                    corti_s))\n",
    "# G2M = np.concatenate((dvsc_g2m,corti_g2m))\n",
    "\n",
    "\n",
    "# amplifying S phase (limma, using aligned data not raw counts)\n",
    "data_s = data_after.loc[S,:]\n",
    "design = pd.DataFrame(index=data_s.index.values,\n",
    "                      columns=['fish',\n",
    "                               'fish vs. mouse'])\n",
    "design['fish']=1\n",
    "design['fish vs. mouse']=0\n",
    "\n",
    "design.loc[corti_s,\n",
    "           'fish vs. mouse']=1\n",
    "\n",
    "fit = limma.lmFit(data_s.values.T,\n",
    "                  design.values)\n",
    "\n",
    "fit = limma.eBayes(fit,\n",
    "                   trend=True)\n",
    "\n",
    "de_s = pd.DataFrame(limma.topTable(fit,\n",
    "                    coef=design.shape[1],\n",
    "                    number=data_s.shape[1],\n",
    "                    **{'sort.by':'none'}),\n",
    "                    index=data_s.columns.values)\n",
    "\n",
    "de_s.sort_values('logFC',\n",
    "                 ascending=False,\n",
    "                 inplace=True)\n",
    "\n",
    "# de_dvsc.to_csv('metaAnalysis/results/de_dvsc.csv')\n",
    "\n",
    "print(de_s.loc[de_s.index.values[\\\n",
    "        np.where((de_s['adj.P.Val']<0.001)&\n",
    "        (de_s['logFC'].abs()>np.log2(1.25)))],:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## markers for proliferating fish & mouse cells ## grn inference ##\n",
    "from arboreto.algo import grnboost2\n",
    "limma = importr('limma')\n",
    "\n",
    "# mouse TFs (via TFDB3)\n",
    "mouse_tfs = pd.read_csv('metaAnalysis/refs/mouse_tfs.csv')\n",
    "mouse_tfs.loc[mouse_tfs.index.values[-1]+1,'Symbol'] = 'Cbx5'\n",
    "\n",
    "try:\n",
    "    network = pd.read_csv('metaAnalysis/results/grn.csv',index_col=0)\n",
    "    \n",
    "except:    \n",
    "    # GRN inference with GRNboost2 via Arboreto (all cells, not just near dvsc)\n",
    "    network = grnboost2(expression_data=data_after,\n",
    "                        tf_names=list(mouse_tfs['Symbol']))\n",
    "    network.set_index(np.arange(network.shape[0]),inplace=True)\n",
    "    network['weight'] = network['importance']\n",
    "    network.drop('importance',axis=1,inplace=True)\n",
    "    network.to_csv('metaAnalysis/results/grn.csv')\n",
    "    \n",
    "cut = 4 # cutoff weight for graph edges\n",
    "# plt.figure()\n",
    "# plt.plot(network.index.values,network['weight'])\n",
    "# ax = plt.gca()\n",
    "# l,r = ax.get_xlim()\n",
    "# plt.hlines(cut,l,r,color='r')\n",
    "# ax.set_xlim(l,r)\n",
    "# plt.show()\n",
    "\n",
    "# DE analysis with limma (using integrated data, not raw counts)\n",
    "# cells near dvsc, mouse vs. fish\n",
    "de_data = data_after.loc[np.concatenate((mouse_near_dvsc,dvsc_near_dvsc)),:]\n",
    "design = pd.DataFrame(index=de_data.index.values,\n",
    "                      columns=['fish','fish vs. mouse'])\n",
    "design['fish']=1\n",
    "design['fish vs. mouse']=0\n",
    "design.loc[mouse_near_dvsc,'fish vs. mouse']=1\n",
    "fit = limma.lmFit(de_data.values.T,design.values)\n",
    "fit = limma.eBayes(fit,trend=True)\n",
    "de_dvsc = pd.DataFrame(limma.topTable(fit,\n",
    "                       coef=design.shape[1],\n",
    "                       number=de_data.shape[1],\n",
    "                       **{'sort.by':'none'}),\n",
    "                       index=de_data.columns.values)\n",
    "de_dvsc.sort_values('logFC',ascending=False,inplace=True)\n",
    "de_dvsc.to_csv('metaAnalysis/results/de_dvsc.csv')\n",
    "\n",
    "# choose (in)significant genes from DE analysis\n",
    "cutoff = 1.33\n",
    "ins = de_dvsc.index.values[np.where((de_dvsc['P.Value']>0.05)|\n",
    "                                    (de_dvsc['logFC'].abs()<np.log2(cutoff)))]\n",
    "sig = de_dvsc.index.values[np.where((de_dvsc['P.Value']<0.05)&\n",
    "                                    (de_dvsc['logFC'].abs()>np.log2(cutoff)))]\n",
    "\n",
    "# find GRN for DE genes\n",
    "G = network.loc[network.index.values[np.where((network['weight']>cut)&\n",
    "                np.array([gene in sig for gene in network['TF'].values])&\n",
    "                np.array([gene in sig for gene in network['target'].values]))],:]\n",
    "    \n",
    "# volcano plot\n",
    "plt.figure(figsize=(4,6))\n",
    "plt.scatter(de_dvsc.loc[ins,'logFC'],\n",
    "            -np.log10(de_dvsc.loc[ins,'P.Value']),\n",
    "            c='gray',s=10)\n",
    "plt.scatter(de_dvsc.loc[sig,'logFC'],\n",
    "            -np.log10(de_dvsc.loc[sig,'P.Value']),\n",
    "            c='black',s=10)\n",
    "plt.scatter(de_dvsc.loc[G['TF'].unique(),'logFC'],\n",
    "            -np.log10(de_dvsc.loc[G['TF'].unique(),'P.Value']),\n",
    "            c='indianred',s=10)\n",
    "\n",
    "# draw and annotate cutoffs\n",
    "ax = plt.gca()\n",
    "l,r = ax.get_xlim()\n",
    "b,t = ax.get_ylim()\n",
    "plt.hlines(-np.log10(0.05),-max([l,r]),max([l,r]),\n",
    "           linestyle='--',linewidth=1,color='k',zorder=0)\n",
    "plt.text(s='p = 0.05',x=l-0.075,y=-np.log10(0.05),\n",
    "         va='center',ha='right',fontsize=8)\n",
    "plt.vlines(np.log2(cutoff),b,t,\n",
    "           linestyle='--',linewidth=1,color='k',zorder=0)\n",
    "plt.vlines(-np.log2(cutoff),b,t,\n",
    "           linestyle='--',linewidth=1,color='k',zorder=0)\n",
    "plt.text(s='FC = +/- 1.33',x=0,y=17,ha='center')\n",
    "plt.annotate(s='',xy=(0.22,17),xytext=(0.4,16),\n",
    "             arrowprops=dict(arrowstyle=ArrowStyle.CurveA(),color='k'))\n",
    "plt.annotate(s='',xy=(-0.22,17),xytext=(-0.4,16),\n",
    "             arrowprops=dict(arrowstyle=ArrowStyle.CurveA(),color='k'))\n",
    "ax.set_xlim(-max([l,r]),max([l,r]))\n",
    "ax.set_ylim(b,t)\n",
    "\n",
    "# # show regulation results\n",
    "# print('DE genes: ')\n",
    "# print(de_dvsc.loc[sig,:])\n",
    "# print('\\nRegulation: ')\n",
    "# print(G)\n",
    "# print('\\nRegulation stats: ')\n",
    "# print(G['target'].value_counts().to_frame().reset_index().rename(columns={'index':'target', 'target':'count'}))\n",
    "\n",
    "# annotate genes\n",
    "plt.text(x=np.mean([-max([l,r]),-np.log2(cutoff)]),\n",
    "         s='Cbx5',y=8.8,ha='center',color='indianred')\n",
    "plt.text(x=np.mean([-max([l,r]),-np.log2(cutoff)]),\n",
    "         s='Ccnd2\\nRrm1\\nRrm2\\nRpa1\\nRpa2\\nFen1\\nAhcy',\n",
    "         y=3.5,ha='center',color='royalblue')\n",
    "plt.text(x=np.mean([max([l,r]),np.log2(cutoff)]),\n",
    "         s='Tubb5',y=17.5,ha='center',color='rebeccapurple')\n",
    "plt.text(x=np.mean([max([l,r]),np.log2(cutoff)]),\n",
    "         s='Fos',y=7,ha='center',color='indianred')\n",
    "plt.text(x=np.mean([max([l,r]),np.log2(cutoff)]),\n",
    "         s='Ucp2\\n*Pdia3',y=4.8,ha='center',color='rebeccapurple')\n",
    "\n",
    "# add arrows for GRN\n",
    "plt.annotate(s='',xy=(np.mean([-max([l,r]),-np.log2(cutoff)]),8.7),\n",
    "             xytext=(np.mean([-max([l,r]),-np.log2(cutoff)]),7.6),\n",
    "             arrowprops=dict(arrowstyle=ArrowStyle.CurveA(),color='k'))\n",
    "plt.annotate(s='',xy=(np.mean([max([l,r]),np.log2(cutoff)]),6.9),\n",
    "             xytext=(np.mean([max([l,r]),np.log2(cutoff)]),5.75),\n",
    "             arrowprops=dict(arrowstyle=ArrowStyle.CurveA(),color='k'))\n",
    "plt.annotate(s='',xy=(np.mean([-max([l,r]),-np.log2(cutoff)]),9.2),\n",
    "             xytext=(np.mean([max([l,r]),np.log2(cutoff)]),7.4),\n",
    "             arrowprops=dict(arrowstyle='<->',color='k',\n",
    "             connectionstyle='arc3,rad=1'))\n",
    "\n",
    "# labels and save\n",
    "ax.set_xlabel('log2 FC')\n",
    "ax.set_ylabel('-log10 p value')\n",
    "plt.tight_layout()\n",
    "plt.savefig('metaAnalysis/figures/dvsc_volcano.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## markers for proliferating medial support cells (corti) ##\n",
    "####### REDO WITH DESEQ2 -> ONLY ONE DATASET AT A TIME, RAW READS #########\n",
    "\n",
    "# medial sc IDs: proliferating (near dvsc)\n",
    "mouse_dvsc_meta = metadata.loc[mouse_near_dvsc,:]\n",
    "burns_dvsc_idxs = mouse_dvsc_meta.index.values[np.where((mouse_dvsc_meta['dataset']=='burns et al')&\n",
    "                                                        (mouse_dvsc_meta['organ']=='corti')&\n",
    "                                                        (mouse_dvsc_meta['type']=='sc'))]\n",
    "hoa_dvsc_idxs = mouse_dvsc_meta.index.values[np.where((mouse_dvsc_meta['dataset']=='hoa et al')&\n",
    "                                                      (mouse_dvsc_meta['organ']=='corti')&\n",
    "                                                      (mouse_dvsc_meta['type']=='sc'))]\n",
    "burns_dvsc_medial_idxs = burns.columns.values[np.where((burns.T.loc[burns_dvsc_idxs,['Plp1']].values > 0)|\n",
    "                                                       (burns.T.loc[burns_dvsc_idxs,['Plp2']].values > 0))[0]]\n",
    "hoa_dvsc_medial_idxs = hoa.columns.values[np.where((hoa.T.loc[hoa_dvsc_idxs,['Plp1']].values > 0)|\n",
    "                                                   (hoa.T.loc[hoa_dvsc_idxs,['Plp2']].values > 0))[0]]\n",
    "dvsc_idxs = np.concatenate((burns_dvsc_medial_idxs,hoa_dvsc_medial_idxs))\n",
    "\n",
    "# medial sc IDs: near other\n",
    "mouse_other_meta = metadata.loc[mouse_near_other,:]\n",
    "burns_other_idxs = mouse_other_meta.index.values[np.where((mouse_other_meta['dataset']=='burns et al')&\n",
    "                                                          (mouse_other_meta['organ']=='corti')&\n",
    "                                                          (mouse_other_meta['type']=='sc'))]\n",
    "hoa_other_idxs = mouse_other_meta.index.values[np.where((mouse_other_meta['dataset']=='hoa et al')&\n",
    "                                                        (mouse_other_meta['organ']=='corti')&\n",
    "                                                        (mouse_other_meta['type']=='sc'))]\n",
    "burns_other_medial_idxs = burns.columns.values[np.where((burns.T.loc[burns_other_idxs,['Plp1']].values > 0)|\n",
    "                                                        (burns.T.loc[burns_other_idxs,['Plp2']].values > 0))[0]]\n",
    "hoa_other_medial_idxs = hoa.columns.values[np.where((hoa.T.loc[hoa_other_idxs,['Plp1']].values > 0)|\n",
    "                                                    (hoa.T.loc[hoa_other_idxs,['Plp2']].values > 0))[0]]\n",
    "other_idxs = np.concatenate((burns_other_medial_idxs,hoa_other_medial_idxs))\n",
    "\n",
    "\n",
    "# DE analysis with limma (using integrated data, not raw counts)\n",
    "de_data = data_after.loc[np.concatenate((other_idxs,dvsc_idxs)),:]\n",
    "design = pd.DataFrame(index=de_data.index.values,\n",
    "                      columns=['other','other vs. dvsc'])\n",
    "design['other']=1\n",
    "design['other vs. dvsc']=0\n",
    "design.loc[dvsc_idxs,'other vs. dvsc']=1\n",
    "fit = limma.lmFit(de_data.values.T,design.values)\n",
    "fit = limma.eBayes(fit,trend=True)\n",
    "de_medial = pd.DataFrame(limma.topTable(fit,\n",
    "                         coef=design.shape[1],\n",
    "                         number=de_data.shape[1],\n",
    "                         **{'sort.by':'none'}),\n",
    "                         index=de_data.columns.values)\n",
    "de_medial.sort_values('logFC',ascending=False,inplace=True)\n",
    "de_medial.to_csv('metaAnalysis/results/de_medial.csv')\n",
    "\n",
    "# show top results\n",
    "print(de_medial.head(15))\n",
    "print(de_medial.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "#######################################  PART :    ###################################################\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "# # fit dynamical model (ABC-SMC)\n",
    "# from scipy.integrate import odeint\n",
    "# from pyabc import ABCSMC, RV, Distribution\n",
    "# from pyabc.transition import MultivariateNormalTransition\n",
    "# import tempfile\n",
    "# db_path = (\"sqlite:///\"+os.path.join(tempfile.gettempdir(), \"test.db\"))\n",
    "\n",
    "# # model & distance functions\n",
    "# def Hill(x):\n",
    "#     return (x**2)/(1+x**2)\n",
    "    \n",
    "# def f(y,t,p):     \n",
    "#     x0,x1 = y\n",
    "#     dx0 = (p['c1']*x0 + p['c2']*x1 + p['c3']*x0*x1) * p['v0']\n",
    "#     dx1 = (p['c4']*x0 + p['c5']*x1 + p['c6']*x0*x1) * p['v1']\n",
    "#     dydt = [dx0,dx1]\n",
    "#     return dydt\n",
    "\n",
    "# def model(p):\n",
    "#     t = modules_plot.index.values\n",
    "#     init = modules_plot.loc[t[0],modules.columns.values]\n",
    "#     sim = pd.DataFrame(odeint(f,init,t,args=(p,)))\n",
    "#     return sim\n",
    "\n",
    "# def model_plot(p):\n",
    "#     t = np.linspace(modules_plot.index.values[0],modules_plot.index.values[-1],1000)\n",
    "#     init = modules_plot.loc[t[0],modules.columns.values]\n",
    "#     sim = pd.DataFrame(odeint(f,init,t,args=(p,)))\n",
    "#     sim.set_index(t,inplace=True)\n",
    "#     return sim\n",
    "\n",
    "# def distance(sim,data):\n",
    "#     data = modules_plot[modules.columns.values].values.ravel(order='F')\n",
    "#     sim = sim.values.ravel(order='F')\n",
    "#     res = np.absolute(data - sim)\n",
    "#     wres = res/np.tile(modules_plot['density'],2) \n",
    "#     return wres.sum()\n",
    "\n",
    "\n",
    "# # model parameters / priors\n",
    "# lower = -10\n",
    "# upper = 10-lower\n",
    "\n",
    "# priors = Distribution(\\\n",
    "#                       c1=RV(\"uniform\",lower,upper),\\\n",
    "#                       c2=RV(\"uniform\",lower,upper),\\\n",
    "#                       c3=RV(\"uniform\",lower,upper),\\\n",
    "#                       c4=RV(\"uniform\",lower,upper),\\\n",
    "#                       c5=RV(\"uniform\",lower,upper),\\\n",
    "#                       c6=RV(\"uniform\",lower,upper),\\\n",
    "#                       v0=RV(\"uniform\",0.1,10.1),\\\n",
    "#                       v1=RV(\"uniform\",0.1,10.1),\\\n",
    "#                       )\n",
    "    \n",
    "# # ABC-SMC\n",
    "# abc = ABCSMC(models=model,parameter_priors=priors,distance_function=distance,population_size=100)\n",
    "# history = abc.new(db_path)\n",
    "# h = abc.run(minimum_epsilon=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot ABC-SMC fits against data\n",
    "# posterior = history.get_population_extended()\n",
    "# posterior.columns = [col.replace('par_','') for col in posterior.columns.values]\n",
    "# posterior = posterior.loc[:,posterior.columns.values[2:-2]]\n",
    "\n",
    "# # simulations\n",
    "# idx_arrays = [np.concatenate((np.zeros(posterior.index.values.shape,dtype=int),np.ones(posterior.index.values.shape,dtype=int))),np.concatenate((posterior.index.values,posterior.index.values))]\n",
    "# idx_tuples = list(zip(*idx_arrays))\n",
    "# index = pd.MultiIndex.from_tuples(idx_tuples, names=['variable','particle'])\n",
    "# simulations = pd.DataFrame(index=np.linspace(modules_plot.index.values[0],modules_plot.index.values[-1],1000),columns=index)\n",
    "# for idx,p in posterior.iterrows():\n",
    "#     sim = model_plot(p)\n",
    "#     simulations[0,idx] = sim[0]\n",
    "#     simulations[1,idx] = sim[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LMFIT\n",
    "# from lmfit import minimize, Parameters, Parameter, report_fit\n",
    "# ##################################################################################################################\n",
    "# # model: \n",
    "# def f(y,t,p):\n",
    "#     # \"forcing\" by delta\n",
    "#     D1 = caudad_data.loc[(caudad_data['x']-t).abs().idxmin(),'ENSDARG00000002336']\n",
    "#     D2 = rostrad_data.loc[(rostrad_data['x']-t).abs().idxmin(),'ENSDARG00000002336']\n",
    "# #     N1,N2,E1,E2,S1,S2 = y\n",
    "#     N1,N2 = y\n",
    "#     dN1dt = (p['B1'] + p['N0'] * (N1**2/(p['a1']+N1**2)) - N1 * (p['gN'] + p['kt']*D2 + p['kc']*D1))*p['tau']\n",
    "#     dN2dt = (p['B1'] + p['N0'] * (N2**2/(p['a1']+N2**2)) - N2 * (p['gN'] + p['kt']*D1 + p['kc']*D2))*p['tau']\n",
    "# #     dE1dt = (p['E0'] * (1/(1+p['b1']*N1**2)) - p['gE']*E1) * p['tau']\n",
    "# #     dE2dt = (p['E0'] * (1/(1+p['b1']*N2**2)) - p['gE']*E2) * p['tau']\n",
    "# #     dS1dt = (p['S0'] * (p['k1']*E1/(p['k2']*N1+p['k1']*E1+p['k1']*p['k2'])) - p['gS']*S1) * p['tau']\n",
    "# #     dS2dt = (p['S0'] * (p['k1']*E2/(p['k2']*N2+p['k1']*E2+p['k1']*p['k2'])) - p['gS']*S2) * p['tau']\n",
    "# #     dydt = [dN1dt,dN2dt,dE1dt,dE2dt,dS1dt,dS2dt]\n",
    "#     dydt = [dN1dt,dN2dt]\n",
    "#     return dydt\n",
    "\n",
    "# # simulate model:\n",
    "# def model(p):\n",
    "#     # ics and simulation times\n",
    "# #     genes = ['ENSDARG00000052139','ENSDARG00000039701','ENSDARG00000077226']\n",
    "#     genes = ['ENSDARG00000052139']\n",
    "#     t = caudad_data['x'].values\n",
    "#     init = [ics[val] for val in range(len(genes)) for ics in\\\n",
    "#             [caudad_data.loc[caudad_data.index.values[0],genes].values,\\\n",
    "#             rostrad_data.loc[rostrad_data.index.values[0],genes].values]]\n",
    "#     sim = pd.DataFrame(odeint(f,init,t,args=(p,)))\n",
    "#     return sim\n",
    "\n",
    "# # # fit model to data:\n",
    "# def residuals(p):\n",
    "#     sim = model(p)\n",
    "# #     genes = ['ENSDARG00000052139','ENSDARG00000039701','ENSDARG00000077226']\n",
    "#     genes = ['ENSDARG00000052139']\n",
    "#     data = pd.concat([caudad_data[genes[0]],rostrad_data[genes[0]]],axis=1)\n",
    "# #     data.columns = ['N1','N2','E1','E2','S1','S2']\n",
    "#     data.columns = ['N1','N2']\n",
    "#     data = data.values.ravel()\n",
    "#     sim = sim.values.ravel()\n",
    "#     return np.absolute(data - sim)\n",
    "# ##################################################################################################################\n",
    "\n",
    "# # parameters: initial values for lmfit\n",
    "# p_init = {}\n",
    "# p_init['tau']=1\n",
    "# p_init['B1']=0.1\n",
    "# p_init['N0']=0.25\n",
    "# # p_init['E0']=10**np.random.uniform(-3,3,1)[0]\n",
    "# # p_init['S0']=10**np.random.uniform(-3,3,1)[0]\n",
    "# p_init['gN']=4\n",
    "# # p_init['gE']=10**np.random.uniform(-3,3,1)[0]\n",
    "# # p_init['gS']=10**np.random.uniform(-3,3,1)[0]\n",
    "# p_init['a1']=0.001\n",
    "# # p_init['b1']=10.405225373860496/10\n",
    "# # p_init['k1']=0.002505764047028155\n",
    "# # p_init['k2']=5.386165535852091\n",
    "# p_init['kt']=80\n",
    "# p_init['kc']=100\n",
    "# # p_init['t_off']=0.1\n",
    "                       \n",
    "# params = Parameters()\n",
    "# # timescale\n",
    "# params.add('tau',value=p_init['tau'],min=0.1,max=5)\n",
    "# # production rates\n",
    "# params.add('B1',value=p_init['B1'],min=0.01,max=2)\n",
    "# params.add('N0',value=p_init['N0'],min=0.1,max=10)\n",
    "# # params.add('E0',value=p_init['E0'],min=p_init['E0']*10**-5,max=p_init['E0']*10**5)\n",
    "# # params.add('S0',value=p_init['S0'],min=p_init['S0']*10**-5,max=p_init['S0']*10**5)\n",
    "# # degradation rates\n",
    "# params.add('gN',value=p_init['gN'],min=0.1,max=15)\n",
    "# # params.add('gE',value=p_init['gE'],min=p_init['gE']*10**-5,max=p_init['gE']*10**5)\n",
    "# # params.add('gS',value=p_init['gS'],min=p_init['gS']*10**-5,max=p_init['gS']*10**5)\n",
    "# # threshold parameters, a,b,k\n",
    "# params.add('a1',value=p_init['a1'],min=0.00001,max=0.01)\n",
    "# # params.add('b1',value=p_init['b1'],min=p_init['b1']*10**-5,max=p_init['b1']*10**5)\n",
    "# # params.add('k1',value=p_init['k1'],min=p_init['k1']*10**-5,max=p_init['k1']*10**5)\n",
    "# # params.add('k2',value=p_init['k2'],min=p_init['k2']*10**-5,max=p_init['k2']*10**5)\n",
    "# # trans-activation and cis-inhibition\n",
    "# params.add('kt',value=p_init['kt'],min=10,max=300)\n",
    "# params.add('kc',value=p_init['kc'],min=10,max=300)\n",
    "\n",
    "# # params.add('t_off',value=p_init['t_off'],min=0,max=1)\n",
    "\n",
    "# fit = minimize(residuals,params,method='leastsq')\n",
    " \n",
    "# report_fit(fit)   \n",
    "        \n",
    "# fit_params = fit.params\n",
    "# p_fit = {}\n",
    "# for param in fit_params:\n",
    "#     p_fit[param] = fit_params[param].value\n",
    "\n",
    "# # p_fit = p_init\n",
    "\n",
    "# # simulate\n",
    "# sim = model(p_fit)\n",
    "# sim['x'] = caudad_data['x'].values\n",
    "\n",
    "# colors = ['tab:blue','tab:red']\n",
    "# genes = ['ENSDARG00000052139','ENSDARG00000039701','ENSDARG00000077226']\n",
    "\n",
    "# n=0 # notch3\n",
    "# ax = caudad_data.plot(kind='line',figsize=(10,3),color=colors[0],x='x',y=genes[n],ls='dotted')\n",
    "# rostrad_data.plot(kind='line',ax=ax,figsize=(10,3),color=colors[1],x='x',y=genes[n],ls='dotted')\n",
    "# sim.plot(kind='line',ax=ax,figsize=(10,3),color=colors[0],x='x',y=2*n)\n",
    "# sim.plot(kind='line',ax=ax,figsize=(10,3),color=colors[1],x='x',y=2*n+1)\n",
    "# ax.legend(['caudad','rostrad'],ncol=2,loc=1)\n",
    "# ax.set_title('notch3')\n",
    "# ax.set_xlabel('time (AU)')\n",
    "# ax.set_ylabel('Expression (AU)')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('notch3_fits.png',dpi=300)\n",
    "\n",
    "# n=1 # emx2\n",
    "# caudad_data.plot(kind='line',ax=ax[n],figsize=(10,10),color=colors[0],x='x',y=genes[n],ls='dotted')\n",
    "# rostrad_data.plot(kind='line',ax=ax[n],figsize=(10,10),color=colors[1],x='x',y=genes[n],ls='dotted')\n",
    "# # sim.plot(kind='line',ax=ax[n],figsize=(10,10),color=colors[0],x='x',y=2*n)\n",
    "# # sim.plot(kind='line',ax=ax[n],figsize=(10,10),color=colors[1],x='x',y=2*n+1)\n",
    "# ax[n].legend(['caudad','rostrad'],ncol=2,loc=2)\n",
    "# ax[n].set_title('emx2')\n",
    "# ax[n].set_xlabel('time (AU)')\n",
    "# ax[n].set_ylabel('Expression (AU)')\n",
    "\n",
    "# n=2 # smarca4a\n",
    "# caudad_data.plot(kind='line',ax=ax[n],figsize=(10,10),color=colors[0],x='x',y=genes[n],ls='dotted')\n",
    "# rostrad_data.plot(kind='line',ax=ax[n],figsize=(10,10),color=colors[1],x='x',y=genes[n],ls='dotted')\n",
    "# # sim.plot(kind='line',ax=ax[n],figsize=(10,10),color=colors[0],x='x',y=2*n)\n",
    "# # sim.plot(kind='line',ax=ax[n],figsize=(10,10),color=colors[1],x='x',y=2*n+1)\n",
    "# ax[n].legend(['caudad','rostrad'],ncol=2,loc=2)\n",
    "# ax[n].set_title('smarca4a')\n",
    "# ax[n].set_xlabel('time (AU)')\n",
    "# ax[n].set_ylabel('Expression (AU)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SINDy w/ parameterized thresholding\n",
    "# from scipy.integrate import odeint\n",
    "# from pysindy.feature_library import CustomLibrary\n",
    "# from pysindy.optimizers import STLSQ\n",
    "# # from scipy.optimize import differential_evolution, Bounds\n",
    "# from pyabc import ABCSMC, RV, Distribution\n",
    "# from pyabc.transition import MultivariateNormalTransition\n",
    "# import tempfile\n",
    "# db_path = (\"sqlite:///\"+os.path.join(tempfile.gettempdir(), \"test.db\"))\n",
    "\n",
    "# def Hill(x):\n",
    "#     return (x**2)/(1+x**2)\n",
    "\n",
    "# def f(y,t,coef):    \n",
    "#     x0,x1,x2 = y\n",
    "#     dx0dt = coef[0,0]*Hill(x0) + coef[0,1]*Hill(x1) + coef[0,2]*Hill(x2)\n",
    "#     dx1dt = coef[1,0]*Hill(x0) + coef[1,1]*Hill(x1) + coef[1,2]*Hill(x2)\n",
    "#     dx2dt = coef[2,0]*Hill(x0) + coef[2,1]*Hill(x1) + coef[2,2]*Hill(x2)\n",
    "#     dydt = [dx0dt,dx1dt,dx2dt]\n",
    "#     return dydt\n",
    "\n",
    "# def distance(sim,y):\n",
    "#     resid = np.absolute(modules.values.flatten() - sim.values.flatten()).sum()/len(sim.values.flatten())\n",
    "#     return resid\n",
    "    \n",
    "# def sindyf(p):\n",
    "#     functions = [lambda x: Hill(x)]\n",
    "# #                  lambda x: x**2/(1+x**2) * x**2/(1+x**2),\\\n",
    "# #                  lambda x,y: x**2/(1+x**2) * y**2/(1+y**2)]\n",
    "#     lib = CustomLibrary(library_functions=functions)\n",
    "#     opt = STLSQ(threshold=p['threshold'],alpha=p['alpha'])\n",
    "#     model = SINDy(optimizer=opt,feature_library=lib)\n",
    "#     model.fit(modules.values, t=modules.index.values[1])\n",
    "#     coef = model.coefficients()\n",
    "    \n",
    "#     # simulate sparse solution\n",
    "#     t = modules.index.values\n",
    "#     init = modules.loc[t[0],:]\n",
    "#     sim = odeint(f,init,t,args=(coef,))\n",
    "#     sim = pd.DataFrame(sim)\n",
    "\n",
    "#     return sim\n",
    "    \n",
    "# # bounds = Bounds([0],[2])\n",
    "# # res = differential_evolution(sindyf,bounds=bounds,args=(alpha,False,))\n",
    "# # cost,model = sindyf(res.x,alpha,True)\n",
    "# # print(cost)\n",
    "# # model.print()\n",
    "\n",
    "\n",
    "# priors = Distribution(threshold=RV(\"uniform\",0,1),alpha=RV(\"uniform\",0,1))\n",
    "# abc = ABCSMC(models=sindyf,parameter_priors=priors,distance_function=distance,population_size=100)\n",
    "# history = abc.new(db_path)\n",
    "# h = abc.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
