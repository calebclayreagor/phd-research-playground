{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](neuromasts.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuromast single cell pipeline \n",
    "\n",
    "**Caleb Reagor, Rockefeller University**\n",
    "\n",
    "Notebook summary:\n",
    "* Cluster gene trajectories into modules\n",
    "* Analyze pathway enrichment in pseudotime\n",
    "* Differential expression analysis of hair cell polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script dependencies\n",
    "import h5py, rpy2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# custom class for sc datasets\n",
    "from dataset import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R interface via rpy2\n",
    "from rpy2 import robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "from rpy2.robjects import pandas2ri\n",
    "numpy2ri.activate()\n",
    "pandas2ri.activate()\n",
    "base = importr(\"base\")\n",
    "dollar = base.__dict__[\"$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi']= 1000\n",
    "\n",
    "from IPython.display import Markdown\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load data from Lush et al., 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lush = dataset(name='lush et al')\n",
    "\n",
    "# load GEO dataset from hdf5 file\n",
    "f = h5py.File(('geo-datasets/GSE123241/'\n",
    "               'GSE123241.h5'),'r')\n",
    "    \n",
    "group = 'danRer10.Ens_84'\n",
    "\n",
    "lush.raw_counts_from_sparse_matrix(\n",
    "    \n",
    "    cell_names = [i.decode('ascii') for i in f[group]['barcodes'][:]],\n",
    "    gene_names = [i.decode('ascii') for i in f[group]['genes'][:]], \n",
    "    data = f[group]['data'], dtype = 'i4', indices = f[group]['indices'],\n",
    "    indptr = f[group]['indptr'], shape = tuple(reversed(f[group]['shape'])) )\n",
    "\n",
    "# load pseudotime/clustering from fig 4I\n",
    "lush4i = pd.read_csv(('geo-datasets/GSE123241/'\n",
    "                      'lush_fig4i.csv'),\n",
    "                     index_col=0)\n",
    "\n",
    "lush4i.sort_values('pseudotime', inplace=True)\n",
    "\n",
    "display(Markdown('### Raw counts'))\n",
    "display(lush.raw_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lush_sema7a = dataset(name='lush et al sem7a')\n",
    "\n",
    "# load GEO dataset from hdf5 file\n",
    "f = h5py.File(('geo-datasets/GSE123241/'\n",
    "               'GSE123241_sema7a.h5'),'r')\n",
    "\n",
    "lush_sema7a.raw_counts_from_sparse_matrix(\n",
    "    \n",
    "    cell_names = [i.decode('ascii') for i in f['matrix']['barcodes'][:]],\n",
    "    gene_names = [i.decode('ascii') for i in f['matrix']['features']['id'][:]], \n",
    "    data = f['matrix']['data'], dtype = 'i4', indices = f['matrix']['indices'],\n",
    "    indptr = f['matrix']['indptr'], shape = tuple(reversed(f['matrix']['shape'])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sema7a: all transcripts (GRCz10)\n",
    "lush.raw_counts['ENSDARG00000078707'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sema7a: long transcript (GRCz11)\n",
    "lush_sema7a.raw_counts['ENSDART00000127274.4'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sema7a: short transcript (GRCz11)\n",
    "lush_sema7a.raw_counts['ENSDART00000156179.2'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process, scale and impute expression\n",
    "# * filter rare genes and cells with low counts\n",
    "# * normalize library sizes, then log scale\n",
    "# * impute expression using data diffusion\n",
    "\n",
    "lush.preprocess_raw_counts(library_size_cutoff=0) # pre-filtered\n",
    "\n",
    "display(Markdown('### Filtered, normalized and scaled counts'))\n",
    "display(lush.normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lush.impute_from_normalized(genes='all_genes')\n",
    "\n",
    "display(Markdown('### Imputed counts'))\n",
    "display(lush.imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataset object for differentiating hair cell trajectory\n",
    "diff_traj = dataset(name='diff hair cell trajectory')\n",
    "\n",
    "# cell barcodes for cells in the trajectory\n",
    "trajectory = lush4i.loc[lush4i['cluster'].isin([14,4,2,1])].index\n",
    "\n",
    "# assign expression values from lush dataset object\n",
    "diff_traj.raw_counts = lush.raw_counts.loc[trajectory]\n",
    "diff_traj.normalized = lush.normalized.loc[trajectory]\n",
    "diff_traj.imputed = lush.imputed.loc[trajectory]\n",
    "\n",
    "display(Markdown('### Differentiating hair cell trajectory (imputed counts)'))\n",
    "display(diff_traj.imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign pseudotime/clustering from lush et al figure 4I\n",
    "diff_traj.pseudotimes = lush4i.loc[trajectory,'pseudotime']\n",
    "diff_traj.clusters = lush4i.loc[trajectory,'cluster']\n",
    "\n",
    "display(Markdown('### Trajectory pseudotimes'))\n",
    "display(diff_traj.pseudotimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cluster gene trajectories into modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lateral line genes (lush et al. & zfin)\n",
    "lat_line = pd.read_csv('refs/drerio_latline.csv')\n",
    "\n",
    "# bin data in pseudotime and expression domains:\n",
    "# * binning in pseudotime spaces the data more evenly\n",
    "# *** performed via simple histogram binning\n",
    "# * binning in expression allows us to calculate MI \n",
    "# *** performed via Bayesian blocks adaptive binning\n",
    "\n",
    "diff_traj.bin_data(data = 'imputed', in_pt = True, pt_bin = 0.025,\n",
    "                   genes = lat_line['Ensembl_id'].unique())\n",
    "\n",
    "display(Markdown('### Bin imputed data in pseudotime and expression'))\n",
    "display(diff_traj.binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find pairwise gene similarities (adjusted MI)\n",
    "diff_traj.find_gene_similarities(n_runs=10)\n",
    "\n",
    "display(Markdown('### Gene similarities (Adjusted Mutual Information)'))\n",
    "display(diff_traj.gene_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal number of clusters using spectral clustering and silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_traj.cluster_genes(n_components=2, max_clusters=20, plot_silhouette=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot average gene module trajectories and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot smoothened average and errors for each module\n",
    "diff_traj.plot_modules(data='imputed', smoothing=0.1)\n",
    "\n",
    "# add labels for cell stage\n",
    "for ax in diff_traj.module_axes:\n",
    "    y, a, z, v = 0.5, 0.33, 0, 'center'\n",
    "    ax.text(diff_traj.pseudotimes.iloc[np.where(diff_traj.clusters==14)].min(),\n",
    "            y, 'central s.c.', va=v, ha='left', alpha=a, zorder=z)\n",
    "    ax.text(diff_traj.pseudotimes.iloc[np.where(diff_traj.clusters==4)].max(),\n",
    "            y, 'diff. s.c.', va=v, ha='left', alpha=a, zorder=z)\n",
    "    ax.text(diff_traj.pseudotimes.iloc[np.where(diff_traj.clusters==2)].mean(),\n",
    "            y, 'young h.c.', va=v, ha='center', alpha=a, zorder=z)\n",
    "    ax.text(diff_traj.pseudotimes.iloc[np.where(diff_traj.clusters==1)].mean(),\n",
    "            y, 'mature h.c.', va=v, ha='center', alpha=a, zorder=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell signaling pathway enrichment in pseudotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order genes along pseudotime axis\n",
    "# * criteria: maximum expression pseudotime\n",
    "\n",
    "diff_traj.order_genes_pt(method='max')\n",
    "\n",
    "display(Markdown('### Maximum expression'))\n",
    "display(diff_traj.genes_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin genes in pseudotime and perform GO analysis\n",
    "# * term enrichment for KEGG pathways via Enrichr\n",
    "\n",
    "display(Markdown('### GO term enrichment for developmental cell signaling pathways'))\n",
    "\n",
    "diff_traj.pathway_ea_in_pt(pathways = ['Cell cycle',\n",
    "                           'Notch signaling pathway',\n",
    "                           'Wnt signaling pathway',\n",
    "                           'Hedgehog signaling pathway',\n",
    "                           'TGF-beta signaling pathway'],\n",
    "                            pt_bin=0.09999, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Find differentially expressed genes between hair cells of opposite polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new dataset object for polarizing hair cells\n",
    "# pols = dataset(name='polarizing hair cells')\n",
    "\n",
    "# # cell barcodes for differentiating central support cells\n",
    "# cells = lush4i.loc[lush4i['cluster'].isin([14,4])].index\n",
    "\n",
    "# # assign data from previous trajectory dataset object\n",
    "# pols.raw_counts = diff_traj.raw_counts.loc[cells]\n",
    "# pols.normalized = diff_traj.normalized.loc[cells]\n",
    "# pols.imputed = diff_traj.imputed.loc[cells]\n",
    "# pols.pseudotimes = diff_traj.pseudotimes[cells]\n",
    "# pols.clusters = diff_traj.clusters[cells]\n",
    "\n",
    "# display(Markdown('### Hair cells undergoing the polarity determination (imputed counts)'))\n",
    "# display(pols.imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed cells in low dimensions using known polarity genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load polarity genes: deltas, notch genes, emx2\n",
    "# pol_genes = pd.read_csv('refs/polarity_genes.csv')\n",
    "# pol_genes.set_index('Ensembl_id', drop=False, inplace=True)\n",
    "# g = pol_genes['Ensembl_id'].isin(pols.imputed.columns).index\n",
    "# g_names = pol_genes.loc[g]\n",
    "# g_names.drop('Ensembl_id', axis=1, inplace=True)\n",
    "\n",
    "# # dimensionality reduction\n",
    "# pols.embed_pca(data='imputed', \n",
    "#                n_components=5, \n",
    "#                genes=g)\n",
    "\n",
    "# # t-stochastic neighbor embedding\n",
    "# pols.embed_tsne(data='pca')\n",
    "\n",
    "# display(Markdown('### Polarity genes'))\n",
    "# display(g_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a principal curve to the differentiating hair cell trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use the princurve package in R\n",
    "# princurve = importr('princurve', on_conflict='warn')\n",
    "# pc = princurve.principal_curve(pols.tsne_embedding.values)\n",
    "# cur = np.array(dollar(pc,'s'))\n",
    "# ordr = np.array(dollar(pc,'ord')) - 1\n",
    "\n",
    "# pol_point = -35 # polarization point\n",
    "# tsne1_pre = cur[ordr,0][:pol_point+1]\n",
    "# tsne2_pre = cur[ordr,1][:pol_point+1]\n",
    "# tsne1_pol = cur[ordr,0][pol_point:]\n",
    "# tsne2_pol = cur[ordr,1][pol_point:]\n",
    "\n",
    "# # new cluster labels for hair cells split by principal curve\n",
    "# new_labels = pols.tsne_embedding.iloc[ordr,1][pol_point:] > tsne2_pol\n",
    "# pols.clusters.loc[new_labels.index] = new_labels.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the polarity tsne and principal curve\n",
    "# pols.plot_embedding(data='tsne', ar=0.6, \n",
    "#                     labels=['central s.c.', \n",
    "#                             'diff s.c.', \n",
    "#                             'polarity0',\n",
    "#                             'polarity1'])\n",
    "\n",
    "# pols.embedding_axes.plot(tsne1_pol, \n",
    "#                          tsne2_pol, \n",
    "#                          c='gray')\n",
    "\n",
    "# pols.embedding_axes.plot(tsne1_pre, \n",
    "#                          tsne2_pre,\n",
    "#                          linestyle='--', \n",
    "#                          c='gray')\n",
    "# display(Markdown('### A principal curve separates differentiating hair cells of opposite polarities'))\n",
    "# display(Markdown('* tSNE embedding based only on genes known to participate in the polarity determination'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for differential gene expression between cells of opposite polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # deseq2 diff expression analysis\n",
    "# pols.diff_exp2(clusters=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot expression of known polarity genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pols.plot_violin(clusters=[0,1], cluster_labels=['polarity0', 'polarity1'],\n",
    "#                  gene=g_names.index[5], gene_label=g_names['gene_name'].values[5], ar=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pols.plot_violin(clusters=[0,1], cluster_labels=['polarity0', 'polarity1'],\n",
    "#                  gene='ENSDARG00000054562', gene_label='her15.1', ar=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Align (single cell) psuedotime to (confocal) real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_traj.plot_gene(gene='ENSDARG00000042141', title='myo6b', smoothing=0.1, data='imputed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Find differentially expressed transcription factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeseq = importr('tradeSeq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare single cell data (transcription factors only) for DE testing\n",
    "\n",
    "tfs = pd.read_csv('refs/drerio_animaltfdb3.csv', index_col=0)\n",
    "counts = diff_traj.raw_counts.loc[:,diff_traj.normalized.columns].T\n",
    "counts = counts.loc[np.intersect1d(counts.index, tfs.index),:]\n",
    "pseudotime = np.expand_dims(diff_traj.pseudotimes.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the optimal number of knots for fitting each gene's model\n",
    "\n",
    "# icMat = tradeseq.evaluateK(counts=counts.values, pseudotime=pseudotime, \n",
    "#                            cellWeights=np.ones(pseudotime.shape), \n",
    "#                            k=np.arange(3,20, dtype=int), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit each gene's model and test for DE through pseudotime\n",
    "\n",
    "k = 5 ## optimal k, from above\n",
    "sce = tradeseq.fitGAM(counts=counts.values, pseudotime=pseudotime, \n",
    "                      cellWeights=np.ones(pseudotime.shape), \n",
    "                      nknots=k, verbose=False)\n",
    "\n",
    "assoRes = tradeseq.associationTest(sce)\n",
    "assoRes.set_index(counts.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for significantly varying genes and save to file\n",
    "\n",
    "# p = 1e-5 ## p-value cutoff for DE genes \n",
    "# diffex_tfs = assoRes.loc[assoRes['pvalue']<p,:].copy()\n",
    "# diffex_tfs.drop(['waldStat','df','pvalue'], axis=1, inplace=True)\n",
    "# diffex_tfs['gene_name'] = tfs.loc[diffex_tfs.index].values\n",
    "# diffex_tfs.to_csv('refs/diffex_tfs.csv')\n",
    "diffex_tfs = pd.read_csv('refs/diffex_tfs.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot DE genes previously identified in Lush et al., 2019\n",
    "\n",
    "supp11 = pd.read_csv('geo-datasets/lush_supp11.csv', index_col=0)\n",
    "tfs_to_plot = [x for x in supp11.index if x in diffex_tfs.index]\n",
    "# tfs_to_plot.append(tfs.index[tfs['gene_name']=='foxj1a'].values[0])\n",
    "\n",
    "# dpi_prev = mpl.rcParams['figure.dpi']\n",
    "# mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(diff_traj.normalized[tfs_to_plot].T, xticklabels=False,\n",
    "            yticklabels=tfs.loc[tfs_to_plot].values.ravel(), cbar=False)\n",
    "plt.xlabel('pseudotime ->')\n",
    "# plt.show() \n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/diffex_tfs')\n",
    "\n",
    "# mpl.rcParams['figure.dpi'] = dpi_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Plot FIMO results showing TFBS occurences in TF promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimo = pd.read_csv('refs/fimo_out_500bp/fimo.tsv', sep='\\t').iloc[:-3,:]\n",
    "genes = np.union1d(fimo['motif_id'].unique(), fimo['sequence_name'].unique())\n",
    "\n",
    "tfbs = pd.DataFrame(0, columns=genes, index=genes)\n",
    "for idx in fimo.index: tfbs.loc[fimo.loc[idx,'motif_id'], fimo.loc[idx,'sequence_name']] += 1\n",
    "\n",
    "# annot = tfbs.loc[tfs_to_plot, tfs_to_plot].copy().astype(str)\n",
    "# annot[annot=='0']=''\n",
    "\n",
    "# sns.heatmap(tfbs.loc[tfs_to_plot, tfs_to_plot], \n",
    "#             xticklabels=tfs.loc[tfs_to_plot].values.ravel(),\n",
    "#             yticklabels=tfs.loc[tfs_to_plot].values.ravel(),\n",
    "#             linewidths=0.5, square=True, cbar=False, \n",
    "#             annot=annot, fmt='');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proportions:')\n",
    "\n",
    "for i in np.arange(1,tfbs.values.max(axis=None)+1):\n",
    "    print(f'{i}: {tfbs.values[tfbs==i].size/tfbs.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_traj.normalized[tfbs.columns].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfbs_ = tfbs.copy()\n",
    "tfbs_.iloc[[np.arange(tfbs.shape[0])]*2] = 0\n",
    "tfbs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lasso import inference\n",
    "\n",
    "_, adj = inference(sce=diff_traj.normalized[tfbs.columns].astype(np.float64), tfbs=tfbs_.astype(np.float64), Λ=0.01, σ=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from IPython.display import Image\n",
    "\n",
    "G = nx.convert_matrix.from_pandas_adjacency(adj, create_using=nx.DiGraph)\n",
    "\n",
    "# for i,j in G.edges:\n",
    "#     if adj.loc[i,j] < 0:\n",
    "#         G[i][j]['arrowhead'] = 'box'\n",
    "        \n",
    "# G.graph['node'] = {'shape' : 'circle',\n",
    "#                    'fixedsize' : 'True',\n",
    "#                    'fontsize' : '20'}\n",
    "\n",
    "# G.graph['edge'] = {'arrowsize' : '1.0'}\n",
    "\n",
    "G = nx.relabel_nodes(G, {i:tfs.at[i,'gene_name'] for i in G.nodes()})\n",
    "\n",
    "outdeg = G.out_degree()\n",
    "G.remove_nodes_from([n[0] for n in outdeg if n[1]<2])\n",
    "\n",
    "# outdeg = G.out_degree()\n",
    "# G.remove_nodes_from([n[0] for n in outdeg if n[1]==0])\n",
    "\n",
    "A = nx.nx_agraph.to_agraph(G)\n",
    "A.layout('dot')\n",
    "Image(A.draw(format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in G.nodes(): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_ordered = ['prdm1a','casz1','foxj1a','sox11b','fosl1a','her15.2','her4.2','her4.1','her15.1']\n",
    "\n",
    "plot_these = [tfs.index[tfs['gene_name']==i].values[0] for i in genes_ordered]\n",
    "\n",
    "dpi_prev = mpl.rcParams['figure.dpi']\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(diff_traj.normalized[plot_these].T, xticklabels=False,\n",
    "            yticklabels=tfs.loc[plot_these].values.ravel(), cbar=False)\n",
    "plt.show() \n",
    "\n",
    "mpl.rcParams['figure.dpi'] = dpi_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "hv.extension('matplotlib')\n",
    "hv.output(fig='svg', size=200)\n",
    "\n",
    "sources, targets = tfbs.values.nonzero()\n",
    "edges = pd.DataFrame(index=range(sources.size), columns=['source','target','value'])\n",
    "\n",
    "for idx in edges.index: edges.loc[idx,:] = sources[idx],targets[idx],tfbs.iloc[sources[idx],targets[idx]]\n",
    "nodes = hv.Dataset(pd.DataFrame(tfs.loc[tfbs.index.values].values, columns=['gene']), 'index')\n",
    "    \n",
    "circos_tfbs= hv.Chord((edges, nodes)).opts(opts.Chord(cmap='Category20b', labels='gene',\n",
    "                                                      edge_color=dim('source').astype(str), \n",
    "                                                      node_color=dim('index').astype(str)))\n",
    "\n",
    "hv.save(circos_tfbs, 'figures/circos_tfbs.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources, targets = np.meshgrid(range(tfbs.shape[0]), range(tfbs.shape[1]))\n",
    "edges = pd.DataFrame(index=range(sources.size), columns=['source','target','value'])\n",
    "\n",
    "for idx in edges.index: edges.loc[idx,:] = sources.ravel()[idx], targets.ravel()[idx], 1\n",
    "edges = edges.sample(frac=1)\n",
    "nodes = hv.Dataset(pd.DataFrame(tfs.loc[tfbs.index.values].values, columns=['gene']), 'index')\n",
    "    \n",
    "circos_all = hv.Chord((edges, nodes)).opts(opts.Chord(cmap='Category20b', labels='gene',\n",
    "                                                      edge_color=dim('source').astype(str), \n",
    "                                                      node_color=dim('index').astype(str)))\n",
    "plt.tight_layout()\n",
    "hv.save(circos_all, 'figures/circos_all.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohta = dataset(name='ohta et al')\n",
    "\n",
    "# load GEO dataset from hdf5 file\n",
    "f = h5py.File(('geo-datasets/GSE152859/'\n",
    "               'GSE152859.h5'),'r')\n",
    "\n",
    "ohta.raw_counts_from_sparse_matrix(\n",
    "    \n",
    "    cell_names = [i.decode('ascii') for i in f['matrix']['barcodes'][:]],\n",
    "    gene_names = [i.decode('ascii') for i in f['matrix']['features']['id'][:]], \n",
    "    data = f['matrix']['data'], dtype = 'i4', indices = f['matrix']['indices'],\n",
    "    indptr = f['matrix']['indptr'], shape = tuple(reversed(f['matrix']['shape'])) )\n",
    "\n",
    "display(Markdown('### Raw counts'))\n",
    "display(ohta.raw_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LAPLACIAN DISTRIBUTION\n",
    "# plt.figure(figsize=(4,2))\n",
    "# plt.hist(np.random.laplace(size=(10000,)), \n",
    "#          bins=100, density=True, ec='w', \n",
    "#          linewidth=0.2, facecolor='k')\n",
    "\n",
    "# x = np.linspace(-10,10,1000)\n",
    "# y = 1/2 * np.exp(-abs(x))\n",
    "\n",
    "# plt.plot(x,y,color='r',linewidth=3)\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# plt.yticks([]); plt.xticks([-5,0,5])\n",
    "# plt.xlim([-10,10])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('figures/laplacian')\n",
    "\n",
    "\n",
    "\n",
    "# # HALFNORMAL DISTRIBUTION\n",
    "# plt.figure(figsize=(4,2))\n",
    "# plt.hist([x for x in np.random.normal(size=(100000,)) if x>0], \n",
    "#          bins=50, density=True, ec='w', linewidth=0.2, facecolor='k')\n",
    "\n",
    "# x = np.linspace(-0.1,4,1000)\n",
    "# y = [2/np.sqrt(2*np.pi) * np.exp(-1/2 * i**2) if i>0 else 0 for i in x]\n",
    "\n",
    "# plt.plot(x,y,color='r', linewidth=4)\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# plt.yticks([]); plt.xticks([0,3])\n",
    "# plt.xlim([-0.1,4])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('figures/halfnormal')\n",
    "\n",
    "\n",
    "\n",
    "# # NORMAL DISTRIBUTION\n",
    "# plt.figure(figsize=(4,2))\n",
    "# plt.hist(np.random.normal(size=(100000,)), \n",
    "#          bins=100, density=True, ec='w', \n",
    "#          linewidth=0.2, facecolor='k')\n",
    "\n",
    "# x = np.linspace(-4,4,1000)\n",
    "# y = [1/np.sqrt(2*np.pi) * np.exp(-1/2 * i**2) for i in x]\n",
    "\n",
    "# plt.plot(x,y,color='r',linewidth=3)\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# plt.yticks([]); plt.xticks([-3,0,3])\n",
    "# plt.xlim([-4,4])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('figures/normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sema7a: all transcripts\n",
    "ohta.raw_counts['ENSDARG00000078707'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hudspeth-lab]",
   "language": "python",
   "name": "conda-env-hudspeth-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
